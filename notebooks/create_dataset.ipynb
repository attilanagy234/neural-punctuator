{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'bert-base-uncased' #albert-base-v1, bert-base-cased, bert-base-uncased\n",
    "data_path = \"D:/Data/neural-punctuator/ted-talks/\"\n",
    "\n",
    "with open(data_path + 'train_texts.txt', 'r', encoding='utf-8') as f:\n",
    "    train_text = f.readlines()\n",
    "with open(data_path + 'dev_texts.txt', 'r', encoding='utf-8') as f:\n",
    "    valid_text = f.readlines()\n",
    "with open(data_path + 'test_texts_2012.txt', 'r', encoding='utf-8') as f:\n",
    "    test_text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = train_text, valid_text, test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1029, 8, 11]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(ds) for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('!', '.')\n",
    "    text = text.replace(':', ',')\n",
    "    text = text.replace('--', ',')\n",
    "    \n",
    "    reg = \"(?<=[a-zA-Z])-(?=[a-zA-Z]{2,})\"\n",
    "    r = re.compile(reg, re.DOTALL)\n",
    "    text = r.sub(' ', text)\n",
    "    \n",
    "    text = re.sub(r'\\s-\\s', ' , ', text)\n",
    "    \n",
    "#     text = text.replace('-', ',')\n",
    "    text = text.replace(';', '.')\n",
    "    text = text.replace(' ,', ',')\n",
    "    text = text.replace('â™«', '')\n",
    "    text = text.replace('...', '')\n",
    "    text = text.replace('.\\\"', ',')\n",
    "    text = text.replace('\"', ',')\n",
    "\n",
    "    text = re.sub(r'--\\s?--', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    text = re.sub(r',\\s?,', ',', text)\n",
    "    text = re.sub(r',\\s?\\.', '.', text)\n",
    "    text = re.sub(r'\\?\\s?\\.', '?', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    text = re.sub(r'\\s+\\?', '?', text)\n",
    "    text = re.sub(r'\\s+,', ',', text)\n",
    "    text = re.sub(r'\\.[\\s+\\.]+', '. ', text)\n",
    "    text = re.sub(r'\\s+\\.', '.', text)\n",
    "    \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [[clean_text(text) for text in ds] for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1029, 8, 11]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len([t for t in ds if len(t)>0]) for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2339461, 17346, 18474]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(' '.join(ds).split(' ')) for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1012, 1029, 1010]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids = tokenizer.encode(\".?,\")[1:-1]\n",
    "target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 1012, '?': 1029, ',': 1010}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token2id = {t: tokenizer.encode(t)[-2] for t in \".?,\"}\n",
    "target_token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1012, 1029, 1010]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids = list(target_token2id.values())\n",
    "target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2target = {\n",
    "    0: 0,\n",
    "    -1: -1,\n",
    "}\n",
    "for i, ti in enumerate(target_ids):\n",
    "    id2target[ti] = i+1\n",
    "target2id = {value: key for key, value in id2target.items()}\n",
    "\n",
    "def create_target(text):\n",
    "    encoded_words, targets = [], []\n",
    "    \n",
    "    words = text.split(' ')\n",
    "\n",
    "    for word in words:\n",
    "        target = 0\n",
    "        for target_token, target_id in target_token2id.items():\n",
    "            if word.endswith(target_token):\n",
    "                word = word.rstrip(target_token)\n",
    "                target = id2target[target_id]\n",
    "\n",
    "        encoded_word = tokenizer.encode(word, add_special_tokens=False)\n",
    "        \n",
    "        for w in encoded_word:\n",
    "            encoded_words.append(w)\n",
    "        for _ in range(len(encoded_word)-1):\n",
    "            targets.append(-1)\n",
    "        targets.append(target)\n",
    "        \n",
    "#         print([tokenizer._convert_id_to_token(ew) for ew in encoded_word], target)\n",
    "        assert(len(encoded_word)>0)\n",
    "\n",
    "    encoded_words = [tokenizer.cls_token_id or tokenizer.bos_token_id] +\\\n",
    "                    encoded_words +\\\n",
    "                    [tokenizer.sep_token_id or tokenizer.eos_token_id]\n",
    "    targets = [-1] + targets + [-1]\n",
    "    \n",
    "    return encoded_words, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tyranosaurus: kill me? Not enough, -- said the co-pilot -- ...\n",
      "tyranosaurus, kill me? not enough, said the co pilot,\n",
      "[-1, -1, -1, 3, 0, 2, 0, 3, 0, 0, 0, 3, -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ty',\n",
       " '##rano',\n",
       " '##saurus',\n",
       " 'kill',\n",
       " 'me',\n",
       " 'not',\n",
       " 'enough',\n",
       " 'said',\n",
       " 'the',\n",
       " 'co',\n",
       " 'pilot']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Tyranosaurus: kill me? Not enough, -- said the co-pilot -- ...\"\n",
    "print(s)\n",
    "s = clean_text(s)\n",
    "print(s)\n",
    "data, targets = create_target(s)\n",
    "print(targets)\n",
    "[tokenizer._convert_id_to_token(d) for d in data[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_texts, targets = create_target(transcripts[164])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datasets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e120c7db2b4d0189fc9f4fcd43ea73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1029.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428e30682b20490db10183bea224c787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757070b33a9f4375818330cf6f008fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_texts, targets = [], []\n",
    "\n",
    "for ds in datasets:\n",
    "    x = list(zip(*(create_target(ts) for ts in tqdm(ds))))\n",
    "    encoded_texts.append(x[0])\n",
    "    targets.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]          \t-1\n",
      "it             \t0\n",
      "can            \t0\n",
      "be             \t0\n",
      "a              \t0\n",
      "very           \t0\n",
      "complicated    \t0\n",
      "thing          \t3\n",
      "the            \t0\n",
      "ocean          \t1\n",
      "and            \t0\n",
      "it             \t0\n",
      "can            \t0\n",
      "be             \t0\n",
      "a              \t0\n",
      "very           \t0\n",
      "complicated    \t0\n",
      "thing          \t3\n",
      "what           \t0\n",
      "human          \t0\n",
      "health         \t0\n",
      "is             \t1\n",
      "and            \t0\n",
      "bringing       \t0\n",
      "those          \t0\n",
      "two            \t0\n",
      "together       \t0\n",
      "might          \t0\n",
      "seem           \t0\n",
      "a              \t0\n",
      "very           \t0\n",
      "da             \t-1\n",
      "##unt          \t-1\n",
      "##ing          \t0\n",
      "task           \t3\n",
      "but            \t0\n",
      "what           \t0\n",
      "i              \t-1\n",
      "'              \t-1\n",
      "m              \t0\n",
      "going          \t0\n",
      "to             \t0\n",
      "try            \t0\n",
      "to             \t0\n",
      "say            \t0\n",
      "is             \t0\n",
      "that           \t0\n",
      "even           \t0\n",
      "in             \t0\n",
      "that           \t0\n",
      "complexity     \t3\n",
      "there          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "some           \t0\n",
      "simple         \t0\n",
      "themes         \t0\n",
      "that           \t0\n",
      "i              \t0\n",
      "think          \t3\n",
      "if             \t0\n",
      "we             \t0\n",
      "understand     \t3\n",
      "we             \t0\n",
      "can            \t0\n",
      "really         \t0\n",
      "move           \t0\n",
      "forward        \t1\n",
      "and            \t0\n",
      "those          \t0\n",
      "simple         \t0\n",
      "themes         \t0\n",
      "aren           \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "really         \t0\n",
      "themes         \t0\n",
      "about          \t0\n",
      "the            \t0\n",
      "complex        \t0\n",
      "science        \t0\n",
      "of             \t0\n",
      "what           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "going          \t0\n",
      "on             \t3\n",
      "but            \t0\n",
      "things         \t0\n",
      "that           \t0\n",
      "we             \t0\n",
      "all            \t0\n",
      "pretty         \t0\n",
      "well           \t0\n",
      "know           \t1\n",
      "and            \t0\n",
      "i              \t-1\n",
      "'              \t-1\n",
      "m              \t0\n",
      "going          \t0\n",
      "to             \t0\n",
      "start          \t0\n",
      "with           \t0\n",
      "this           \t0\n",
      "one            \t3\n",
      "if             \t0\n",
      "momma          \t0\n",
      "ain            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "happy          \t3\n",
      "ain            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "nobody         \t0\n",
      "happy          \t1\n",
      "we             \t0\n",
      "know           \t0\n",
      "that           \t3\n",
      "right          \t2\n",
      "we             \t-1\n",
      "'              \t-1\n",
      "ve             \t0\n",
      "experienced    \t0\n",
      "that           \t1\n",
      "and            \t0\n",
      "if             \t0\n",
      "we             \t0\n",
      "just           \t0\n",
      "take           \t0\n",
      "that           \t0\n",
      "and            \t0\n",
      "we             \t0\n",
      "build          \t0\n",
      "from           \t0\n",
      "there          \t3\n",
      "then           \t0\n",
      "we             \t0\n",
      "can            \t0\n",
      "go             \t0\n",
      "to             \t0\n",
      "the            \t0\n",
      "next           \t0\n",
      "step           \t3\n",
      "which          \t0\n",
      "is             \t0\n",
      "that           \t0\n",
      "if             \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "ain            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "happy          \t3\n",
      "ain            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "nobody         \t0\n",
      "happy          \t1\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "the            \t0\n",
      "theme          \t0\n",
      "of             \t0\n",
      "my             \t0\n",
      "talk           \t1\n",
      "and            \t0\n",
      "we             \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "making         \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "pretty         \t0\n",
      "unhappy        \t0\n",
      "in             \t0\n",
      "a              \t0\n",
      "lot            \t0\n",
      "of             \t0\n",
      "different      \t0\n",
      "ways           \t1\n",
      "this           \t0\n",
      "is             \t0\n",
      "a              \t0\n",
      "shot           \t0\n",
      "of             \t0\n",
      "can            \t-1\n",
      "##nery         \t0\n",
      "row            \t0\n",
      "in             \t0\n",
      "1932           \t1\n",
      "can            \t-1\n",
      "##nery         \t0\n",
      "row            \t3\n",
      "at             \t0\n",
      "the            \t0\n",
      "time           \t3\n",
      "had            \t0\n",
      "the            \t0\n",
      "biggest        \t0\n",
      "industrial     \t0\n",
      "canning        \t0\n",
      "operation      \t0\n",
      "on             \t0\n",
      "the            \t0\n",
      "west           \t0\n",
      "coast          \t1\n",
      "we             \t0\n",
      "piled          \t0\n",
      "enormous       \t0\n",
      "amounts        \t0\n",
      "of             \t0\n",
      "pollution      \t0\n",
      "into           \t0\n",
      "the            \t0\n",
      "air            \t0\n",
      "and            \t0\n",
      "into           \t0\n",
      "the            \t0\n",
      "water          \t1\n",
      "rolf           \t0\n",
      "bo             \t-1\n",
      "##lin          \t3\n",
      "who            \t0\n",
      "was            \t0\n",
      "a              \t0\n",
      "professor      \t0\n",
      "at             \t0\n",
      "the            \t0\n",
      "hop            \t-1\n",
      "##kin          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "marine         \t0\n",
      "station        \t0\n",
      "where          \t0\n",
      "i              \t0\n",
      "work           \t3\n",
      "wrote          \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "1940s          \t0\n",
      "that           \t-1\n",
      ",              \t-1\n",
      "the            \t0\n",
      "fu             \t-1\n",
      "##mes          \t0\n",
      "from           \t0\n",
      "the            \t0\n",
      "sc             \t-1\n",
      "##um           \t0\n",
      "floating       \t0\n",
      "on             \t0\n",
      "the            \t0\n",
      "inlet          \t-1\n",
      "##s            \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "bay            \t0\n",
      "were           \t0\n",
      "so             \t0\n",
      "bad            \t0\n",
      "they           \t0\n",
      "turned         \t0\n",
      "lead           \t0\n",
      "based          \t0\n",
      "paints         \t0\n",
      "black          \t3\n",
      "people         \t0\n",
      "working        \t0\n",
      "in             \t0\n",
      "these          \t0\n",
      "can            \t-1\n",
      "##ner          \t-1\n",
      "##ies          \t0\n",
      "could          \t0\n",
      "barely         \t0\n",
      "stay           \t0\n",
      "there          \t0\n",
      "all            \t0\n",
      "day            \t0\n",
      "because        \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "smell          \t3\n",
      "but            \t0\n",
      "you            \t0\n",
      "know           \t0\n",
      "what           \t0\n",
      "they           \t0\n",
      "came           \t0\n",
      "out            \t0\n",
      "saying         \t2\n",
      "they           \t0\n",
      "say            \t-1\n",
      ",              \t-1\n",
      "you            \t0\n",
      "know           \t0\n",
      "what           \t0\n",
      "you            \t0\n",
      "smell          \t2\n",
      "you            \t0\n",
      "smell          \t0\n",
      "money          \t3\n",
      "that           \t0\n",
      "pollution      \t0\n",
      "was            \t0\n",
      "money          \t0\n",
      "to             \t0\n",
      "that           \t0\n",
      "community      \t3\n",
      "and            \t0\n",
      "those          \t0\n",
      "people         \t0\n",
      "dealt          \t0\n",
      "with           \t0\n",
      "the            \t0\n",
      "pollution      \t0\n",
      "and            \t0\n",
      "absorbed       \t0\n",
      "it             \t0\n",
      "into           \t0\n",
      "their          \t0\n",
      "skin           \t0\n",
      "and            \t0\n",
      "into           \t0\n",
      "their          \t0\n",
      "bodies         \t0\n",
      "because        \t0\n",
      "they           \t0\n",
      "needed         \t0\n",
      "the            \t0\n",
      "money          \t1\n",
      "we             \t0\n",
      "made           \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "unhappy        \t1\n",
      "we             \t0\n",
      "made           \t0\n",
      "people         \t0\n",
      "very           \t0\n",
      "unhappy        \t3\n",
      "and            \t0\n",
      "we             \t0\n",
      "made           \t0\n",
      "them           \t0\n",
      "un             \t-1\n",
      "##hea          \t-1\n",
      "##lth          \t-1\n",
      "##y            \t1\n",
      "the            \t0\n",
      "connection     \t0\n",
      "between        \t0\n",
      "ocean          \t0\n",
      "health         \t0\n",
      "and            \t0\n",
      "human          \t0\n",
      "health         \t0\n",
      "is             \t0\n",
      "actually       \t0\n",
      "based          \t0\n",
      "upon           \t0\n",
      "another        \t0\n",
      "couple         \t0\n",
      "simple         \t0\n",
      "ada            \t-1\n",
      "##ges          \t3\n",
      "and            \t0\n",
      "i              \t0\n",
      "want           \t0\n",
      "to             \t0\n",
      "call           \t0\n",
      "that           \t-1\n",
      ",              \t-1\n",
      "pinch          \t0\n",
      "a              \t0\n",
      "min            \t-1\n",
      "##now          \t3\n",
      "hurt           \t0\n",
      "a              \t0\n",
      "whale          \t3\n",
      "the            \t0\n",
      "pyramid        \t0\n",
      "of             \t0\n",
      "ocean          \t0\n",
      "life           \t0\n",
      "now            \t3\n",
      "when           \t0\n",
      "an             \t0\n",
      "eco            \t-1\n",
      "##logist       \t0\n",
      "looks          \t0\n",
      "at             \t0\n",
      "the            \t0\n",
      "ocean          \t3\n",
      "i              \t0\n",
      "have           \t0\n",
      "to             \t0\n",
      "tell           \t0\n",
      "you            \t3\n",
      "we             \t0\n",
      "look           \t0\n",
      "at             \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "in             \t0\n",
      "a              \t0\n",
      "very           \t0\n",
      "different      \t0\n",
      "way            \t3\n",
      "and            \t0\n",
      "we             \t0\n",
      "see            \t0\n",
      "different      \t0\n",
      "things         \t0\n",
      "than           \t0\n",
      "when           \t0\n",
      "a              \t0\n",
      "regular        \t0\n",
      "person         \t0\n",
      "looks          \t0\n",
      "at             \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "because        \t0\n",
      "when           \t0\n",
      "an             \t0\n",
      "eco            \t-1\n",
      "##logist       \t0\n",
      "looks          \t0\n",
      "at             \t0\n",
      "the            \t0\n",
      "ocean          \t3\n",
      "we             \t0\n",
      "see            \t0\n",
      "all            \t0\n",
      "those          \t0\n",
      "inter          \t-1\n",
      "##con          \t-1\n",
      "##ne           \t-1\n",
      "##ctions       \t1\n",
      "we             \t0\n",
      "see            \t0\n",
      "the            \t0\n",
      "base           \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "food           \t0\n",
      "chain          \t3\n",
      "the            \t0\n",
      "plank          \t-1\n",
      "##ton          \t3\n",
      "the            \t0\n",
      "small          \t0\n",
      "things         \t3\n",
      "and            \t0\n",
      "we             \t0\n",
      "see            \t0\n",
      "how            \t0\n",
      "those          \t0\n",
      "animals        \t0\n",
      "are            \t0\n",
      "food           \t0\n",
      "to             \t0\n",
      "animals        \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "middle         \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "pyramid        \t3\n",
      "and            \t0\n",
      "on             \t0\n",
      "so             \t0\n",
      "up             \t0\n",
      "this           \t0\n",
      "diagram        \t1\n",
      "and            \t0\n",
      "that           \t0\n",
      "flow           \t3\n",
      "that           \t0\n",
      "flow           \t0\n",
      "of             \t0\n",
      "life           \t3\n",
      "from           \t0\n",
      "the            \t0\n",
      "very           \t0\n",
      "base           \t0\n",
      "up             \t0\n",
      "to             \t0\n",
      "the            \t0\n",
      "very           \t0\n",
      "top            \t3\n",
      "is             \t0\n",
      "the            \t0\n",
      "flow           \t0\n",
      "that           \t0\n",
      "eco            \t-1\n",
      "##logists      \t0\n",
      "see            \t1\n",
      "and            \t0\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "what           \t0\n",
      "we             \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "trying         \t0\n",
      "to             \t0\n",
      "preserve       \t0\n",
      "when           \t0\n",
      "we             \t0\n",
      "say            \t-1\n",
      ",              \t-1\n",
      "save           \t0\n",
      "the            \t0\n",
      "ocean          \t1\n",
      "heal           \t0\n",
      "the            \t0\n",
      "ocean          \t3\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "that           \t0\n",
      "pyramid        \t1\n",
      "now            \t0\n",
      "why            \t0\n",
      "does           \t0\n",
      "that           \t0\n",
      "matter         \t0\n",
      "for            \t0\n",
      "human          \t0\n",
      "health         \t2\n",
      "because        \t0\n",
      "when           \t0\n",
      "we             \t0\n",
      "jam            \t0\n",
      "things         \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "bottom         \t0\n",
      "of             \t0\n",
      "that           \t0\n",
      "pyramid        \t0\n",
      "that           \t0\n",
      "shouldn        \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "be             \t0\n",
      "there          \t3\n",
      "some           \t0\n",
      "very           \t0\n",
      "frightening    \t0\n",
      "things         \t0\n",
      "happen         \t1\n",
      "poll           \t-1\n",
      "##uta          \t-1\n",
      "##nts          \t3\n",
      "some           \t0\n",
      "poll           \t-1\n",
      "##uta          \t-1\n",
      "##nts          \t0\n",
      "have           \t0\n",
      "been           \t0\n",
      "created        \t0\n",
      "by             \t0\n",
      "us             \t3\n",
      "molecules      \t0\n",
      "like           \t0\n",
      "pc             \t-1\n",
      "##bs           \t0\n",
      "that           \t0\n",
      "can            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "be             \t0\n",
      "broken         \t0\n",
      "down           \t0\n",
      "by             \t0\n",
      "our            \t0\n",
      "bodies         \t1\n",
      "and            \t0\n",
      "they           \t0\n",
      "go             \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "base           \t0\n",
      "of             \t0\n",
      "that           \t0\n",
      "pyramid        \t3\n",
      "and            \t0\n",
      "they           \t0\n",
      "drift          \t0\n",
      "up             \t1\n",
      "they           \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "passed         \t0\n",
      "up             \t0\n",
      "that           \t0\n",
      "way            \t3\n",
      "on             \t0\n",
      "to             \t0\n",
      "predators      \t0\n",
      "and            \t0\n",
      "on             \t0\n",
      "to             \t0\n",
      "the            \t0\n",
      "top            \t0\n",
      "predators      \t3\n",
      "and            \t0\n",
      "in             \t0\n",
      "so             \t0\n",
      "doing          \t3\n",
      "they           \t0\n",
      "accumulate     \t1\n",
      "now            \t3\n",
      "to             \t0\n",
      "bring          \t0\n",
      "that           \t0\n",
      "home           \t3\n",
      "i              \t0\n",
      "thought        \t0\n",
      "i              \t-1\n",
      "'              \t-1\n",
      "d              \t0\n",
      "in             \t-1\n",
      "##vent         \t0\n",
      "a              \t0\n",
      "little         \t0\n",
      "game           \t1\n",
      "we             \t0\n",
      "don            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "really         \t0\n",
      "have           \t0\n",
      "to             \t0\n",
      "play           \t0\n",
      "it             \t1\n",
      "we             \t0\n",
      "can            \t0\n",
      "just           \t0\n",
      "think          \t0\n",
      "about          \t0\n",
      "it             \t0\n",
      "here           \t1\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "the            \t0\n",
      "st             \t-1\n",
      "##yr           \t-1\n",
      "##of           \t-1\n",
      "##oa           \t-1\n",
      "##m            \t0\n",
      "and            \t0\n",
      "chocolate      \t0\n",
      "game           \t1\n",
      "imagine        \t0\n",
      "that           \t0\n",
      "when           \t0\n",
      "we             \t0\n",
      "got            \t0\n",
      "on             \t0\n",
      "this           \t0\n",
      "boat           \t3\n",
      "we             \t0\n",
      "were           \t0\n",
      "all            \t0\n",
      "given          \t0\n",
      "two            \t0\n",
      "st             \t-1\n",
      "##yr           \t-1\n",
      "##of           \t-1\n",
      "##oa           \t-1\n",
      "##m            \t0\n",
      "peanuts        \t1\n",
      "can            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "do             \t0\n",
      "much           \t0\n",
      "with           \t0\n",
      "them           \t3\n",
      "put            \t0\n",
      "them           \t0\n",
      "in             \t0\n",
      "your           \t0\n",
      "pocket         \t1\n",
      "suppose        \t0\n",
      "the            \t0\n",
      "rules          \t0\n",
      "are            \t3\n",
      "every          \t0\n",
      "time           \t0\n",
      "you            \t0\n",
      "offer          \t0\n",
      "somebody       \t0\n",
      "a              \t0\n",
      "drink          \t3\n",
      "you            \t0\n",
      "give           \t0\n",
      "them           \t0\n",
      "the            \t0\n",
      "drink          \t3\n",
      "and            \t0\n",
      "you            \t0\n",
      "give           \t0\n",
      "them           \t0\n",
      "your           \t0\n",
      "st             \t-1\n",
      "##yr           \t-1\n",
      "##of           \t-1\n",
      "##oa           \t-1\n",
      "##m            \t0\n",
      "peanuts        \t0\n",
      "too            \t1\n",
      "what           \t-1\n",
      "'              \t-1\n",
      "ll             \t0\n",
      "happen         \t0\n",
      "is             \t0\n",
      "that           \t0\n",
      "the            \t0\n",
      "st             \t-1\n",
      "##yr           \t-1\n",
      "##of           \t-1\n",
      "##oa           \t-1\n",
      "##m            \t0\n",
      "peanuts        \t0\n",
      "will           \t0\n",
      "start          \t0\n",
      "moving         \t0\n",
      "through        \t0\n",
      "our            \t0\n",
      "society        \t0\n",
      "here           \t3\n",
      "and            \t0\n",
      "they           \t0\n",
      "will           \t0\n",
      "accumulate     \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "drunk          \t-1\n",
      "##est          \t3\n",
      "sting          \t-1\n",
      "##iest         \t0\n",
      "people         \t1\n",
      "there          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "no             \t0\n",
      "mechanism      \t0\n",
      "in             \t0\n",
      "this           \t0\n",
      "game           \t0\n",
      "for            \t0\n",
      "them           \t0\n",
      "to             \t0\n",
      "go             \t0\n",
      "anywhere       \t0\n",
      "but            \t0\n",
      "into           \t0\n",
      "a              \t0\n",
      "bigger         \t0\n",
      "and            \t0\n",
      "bigger         \t0\n",
      "pile           \t0\n",
      "of             \t0\n",
      "ind            \t-1\n",
      "##ige          \t-1\n",
      "##sti          \t-1\n",
      "##ble          \t0\n",
      "st             \t-1\n",
      "##yr           \t-1\n",
      "##of           \t-1\n",
      "##oa           \t-1\n",
      "##m            \t0\n",
      "peanuts        \t1\n",
      "and            \t0\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "exactly        \t0\n",
      "what           \t0\n",
      "happens        \t0\n",
      "with           \t0\n",
      "pd             \t-1\n",
      "##bs           \t0\n",
      "in             \t0\n",
      "this           \t0\n",
      "food           \t0\n",
      "pyramid        \t3\n",
      "they           \t0\n",
      "accumulate     \t0\n",
      "into           \t0\n",
      "the            \t0\n",
      "top            \t0\n",
      "of             \t0\n",
      "it             \t1\n",
      "now            \t0\n",
      "suppose        \t3\n",
      "instead        \t0\n",
      "of             \t0\n",
      "st             \t-1\n",
      "##yr           \t-1\n",
      "##of           \t-1\n",
      "##oa           \t-1\n",
      "##m            \t0\n",
      "peanuts        \t3\n",
      "we             \t0\n",
      "take           \t0\n",
      "these          \t0\n",
      "lovely         \t0\n",
      "little         \t0\n",
      "chocolate      \t-1\n",
      "##s            \t0\n",
      "that           \t0\n",
      "we             \t0\n",
      "get            \t0\n",
      "and            \t0\n",
      "we             \t0\n",
      "had            \t0\n",
      "those          \t0\n",
      "instead        \t1\n",
      "well           \t3\n",
      "some           \t0\n",
      "of             \t0\n",
      "us             \t0\n",
      "would          \t0\n",
      "be             \t0\n",
      "eating         \t0\n",
      "those          \t0\n",
      "chocolate      \t-1\n",
      "##s            \t0\n",
      "instead        \t0\n",
      "of             \t0\n",
      "passing        \t0\n",
      "them           \t0\n",
      "around         \t3\n",
      "and            \t0\n",
      "instead        \t0\n",
      "of             \t0\n",
      "acc            \t-1\n",
      "##um           \t-1\n",
      "##ulating      \t3\n",
      "they           \t0\n",
      "will           \t0\n",
      "just           \t0\n",
      "pass           \t0\n",
      "into           \t0\n",
      "our            \t0\n",
      "group          \t0\n",
      "here           \t0\n",
      "and            \t0\n",
      "not            \t0\n",
      "accumulate     \t0\n",
      "in             \t0\n",
      "any            \t0\n",
      "one            \t0\n",
      "group          \t0\n",
      "because        \t0\n",
      "they           \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "absorbed       \t0\n",
      "by             \t0\n",
      "us             \t1\n",
      "and            \t0\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "the            \t0\n",
      "difference     \t0\n",
      "between        \t0\n",
      "a              \t0\n",
      "pc             \t-1\n",
      "##b            \t0\n",
      "and            \t3\n",
      "say            \t3\n",
      "something      \t0\n",
      "natural        \t0\n",
      "like           \t0\n",
      "an             \t0\n",
      "omega          \t-1\n",
      "-              \t-1\n",
      "3              \t3\n",
      "something      \t0\n",
      "we             \t0\n",
      "want           \t0\n",
      "out            \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "marine         \t0\n",
      "food           \t0\n",
      "chain          \t1\n",
      "pc             \t-1\n",
      "##bs           \t0\n",
      "accumulate     \t1\n",
      "we             \t0\n",
      "have           \t0\n",
      "great          \t0\n",
      "examples       \t0\n",
      "of             \t0\n",
      "that           \t3\n",
      "unfortunately  \t1\n",
      "pc             \t-1\n",
      "##bs           \t0\n",
      "accumulate     \t0\n",
      "in             \t0\n",
      "dolphins       \t0\n",
      "in             \t0\n",
      "sara           \t-1\n",
      "##so           \t-1\n",
      "##ta           \t0\n",
      "bay            \t3\n",
      "in             \t0\n",
      "texas          \t3\n",
      "in             \t0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "north          \t0\n",
      "carolina       \t1\n",
      "they           \t0\n",
      "get            \t0\n",
      "into           \t0\n",
      "the            \t0\n",
      "food           \t0\n",
      "chain          \t1\n",
      "the            \t0\n",
      "dolphins       \t0\n",
      "eat            \t0\n",
      "the            \t0\n",
      "fish           \t0\n",
      "that           \t0\n",
      "have           \t0\n",
      "pc             \t-1\n",
      "##bs           \t0\n",
      "from           \t0\n",
      "the            \t0\n",
      "plank          \t-1\n",
      "##ton          \t3\n",
      "and            \t0\n",
      "those          \t0\n",
      "pc             \t-1\n",
      "##bs           \t3\n",
      "being          \t0\n",
      "fat            \t0\n",
      "soluble        \t3\n",
      "accumulate     \t0\n",
      "in             \t0\n",
      "these          \t0\n",
      "dolphins       \t1\n",
      "now            \t3\n",
      "a              \t0\n",
      "dolphin        \t3\n",
      "mother         \t0\n",
      "dolphin        \t3\n",
      "any            \t0\n",
      "dolphin        \t3\n",
      "there          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "only           \t0\n",
      "one            \t0\n",
      "way            \t0\n",
      "that           \t0\n",
      "a              \t0\n",
      "pc             \t-1\n",
      "##b            \t0\n",
      "can            \t0\n",
      "get            \t0\n",
      "out            \t0\n",
      "of             \t0\n",
      "a              \t0\n",
      "dolphin        \t1\n",
      "and            \t0\n",
      "what           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "that           \t2\n",
      "in             \t0\n",
      "mother         \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "milk           \t1\n",
      "here           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "a              \t0\n",
      "diagram        \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "pc             \t-1\n",
      "##b            \t0\n",
      "load           \t0\n",
      "of             \t0\n",
      "dolphins       \t0\n",
      "in             \t0\n",
      "sara           \t-1\n",
      "##so           \t-1\n",
      "##ta           \t0\n",
      "bay            \t1\n",
      "adult          \t0\n",
      "males          \t3\n",
      "a              \t0\n",
      "huge           \t0\n",
      "load           \t1\n",
      "juveniles      \t3\n",
      "a              \t0\n",
      "huge           \t0\n",
      "load           \t1\n",
      "females        \t0\n",
      "after          \t0\n",
      "their          \t0\n",
      "first          \t0\n",
      "calf           \t0\n",
      "is             \t0\n",
      "already        \t0\n",
      "we             \t-1\n",
      "##ane          \t-1\n",
      "##d            \t3\n",
      "a              \t0\n",
      "lower          \t0\n",
      "load           \t1\n",
      "those          \t0\n",
      "females        \t3\n",
      "they           \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "not            \t0\n",
      "trying         \t0\n",
      "to             \t1\n",
      "those          \t0\n",
      "females        \t0\n",
      "are            \t0\n",
      "passing        \t0\n",
      "the            \t0\n",
      "pc             \t-1\n",
      "##bs           \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "fat            \t0\n",
      "of             \t0\n",
      "their          \t0\n",
      "own            \t0\n",
      "mother         \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "milk           \t0\n",
      "into           \t0\n",
      "their          \t0\n",
      "offspring      \t3\n",
      "and            \t0\n",
      "their          \t0\n",
      "offspring      \t0\n",
      "don            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "survive        \t1\n",
      "the            \t0\n",
      "death          \t0\n",
      "rate           \t0\n",
      "in             \t0\n",
      "these          \t0\n",
      "dolphins       \t3\n",
      "for            \t0\n",
      "the            \t0\n",
      "first          \t0\n",
      "calf           \t0\n",
      "born           \t0\n",
      "of             \t0\n",
      "every          \t0\n",
      "female         \t0\n",
      "dolphin        \t3\n",
      "is             \t0\n",
      "60             \t0\n",
      "to             \t0\n",
      "80             \t0\n",
      "percent        \t1\n",
      "these          \t0\n",
      "mothers        \t0\n",
      "pump           \t0\n",
      "their          \t0\n",
      "first          \t0\n",
      "offspring      \t0\n",
      "full           \t0\n",
      "of             \t0\n",
      "this           \t0\n",
      "poll           \t-1\n",
      "##uta          \t-1\n",
      "##nt           \t3\n",
      "and            \t0\n",
      "most           \t0\n",
      "of             \t0\n",
      "them           \t0\n",
      "die            \t1\n",
      "now            \t3\n",
      "the            \t0\n",
      "mother         \t0\n",
      "then           \t0\n",
      "can            \t0\n",
      "go             \t0\n",
      "and            \t0\n",
      "reproduce      \t3\n",
      "but            \t0\n",
      "what           \t0\n",
      "a              \t0\n",
      "terrible       \t0\n",
      "price          \t0\n",
      "to             \t0\n",
      "pay            \t0\n",
      "for            \t0\n",
      "the            \t0\n",
      "accumulation   \t0\n",
      "of             \t0\n",
      "this           \t0\n",
      "poll           \t-1\n",
      "##uta          \t-1\n",
      "##nt           \t0\n",
      "in             \t0\n",
      "these          \t0\n",
      "animals        \t3\n",
      "the            \t0\n",
      "death          \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "first          \t0\n",
      "born           \t0\n",
      "calf           \t1\n",
      "there          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "another        \t0\n",
      "top            \t0\n",
      "predator       \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "ocean          \t3\n",
      "it             \t0\n",
      "turns          \t0\n",
      "out            \t1\n",
      "that           \t0\n",
      "top            \t0\n",
      "predator       \t3\n",
      "of             \t0\n",
      "course         \t3\n",
      "is             \t0\n",
      "us             \t1\n",
      "and            \t0\n",
      "we             \t0\n",
      "also           \t0\n",
      "are            \t0\n",
      "eating         \t0\n",
      "meat           \t0\n",
      "that           \t0\n",
      "comes          \t0\n",
      "from           \t0\n",
      "some           \t0\n",
      "of             \t0\n",
      "these          \t0\n",
      "same           \t0\n",
      "places         \t1\n",
      "this           \t0\n",
      "is             \t0\n",
      "whale          \t0\n",
      "meat           \t0\n",
      "that           \t0\n",
      "i              \t0\n",
      "photographed   \t0\n",
      "in             \t0\n",
      "a              \t0\n",
      "grocery        \t0\n",
      "store          \t0\n",
      "in             \t0\n",
      "tokyo          \t3\n",
      "or             \t0\n",
      "is             \t0\n",
      "it             \t2\n",
      "in             \t0\n",
      "fact           \t3\n",
      "what           \t0\n",
      "we             \t0\n",
      "did            \t0\n",
      "a              \t0\n",
      "few            \t0\n",
      "years          \t0\n",
      "ago            \t0\n",
      "was            \t0\n",
      "learn          \t0\n",
      "how            \t0\n",
      "to             \t0\n",
      "smug           \t-1\n",
      "##gle          \t0\n",
      "a              \t0\n",
      "molecular      \t0\n",
      "biology        \t0\n",
      "lab            \t0\n",
      "into           \t0\n",
      "tokyo          \t0\n",
      "and            \t0\n",
      "use            \t0\n",
      "it             \t0\n",
      "to             \t0\n",
      "genetically    \t0\n",
      "test           \t0\n",
      "the            \t0\n",
      "dna            \t0\n",
      "out            \t0\n",
      "of             \t0\n",
      "whale          \t0\n",
      "meat           \t0\n",
      "samples        \t0\n",
      "and            \t0\n",
      "identify       \t0\n",
      "what           \t0\n",
      "they           \t0\n",
      "really         \t0\n",
      "were           \t1\n",
      "and            \t0\n",
      "some           \t0\n",
      "of             \t0\n",
      "those          \t0\n",
      "whale          \t0\n",
      "meat           \t0\n",
      "samples        \t0\n",
      "were           \t0\n",
      "whale          \t0\n",
      "meat           \t1\n",
      "some           \t0\n",
      "of             \t0\n",
      "them           \t0\n",
      "were           \t0\n",
      "illegal        \t0\n",
      "whale          \t0\n",
      "meat           \t3\n",
      "by             \t0\n",
      "the            \t0\n",
      "way            \t1\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "another        \t0\n",
      "story          \t1\n",
      "but            \t0\n",
      "some           \t0\n",
      "of             \t0\n",
      "them           \t0\n",
      "were           \t0\n",
      "not            \t0\n",
      "whale          \t0\n",
      "meat           \t0\n",
      "at             \t0\n",
      "all            \t1\n",
      "even           \t0\n",
      "though         \t0\n",
      "they           \t0\n",
      "were           \t0\n",
      "labeled        \t0\n",
      "whale          \t0\n",
      "meat           \t3\n",
      "they           \t0\n",
      "were           \t0\n",
      "dolphin        \t0\n",
      "meat           \t1\n",
      "some           \t0\n",
      "of             \t0\n",
      "them           \t0\n",
      "were           \t0\n",
      "dolphin        \t0\n",
      "liver          \t1\n",
      "some           \t0\n",
      "of             \t0\n",
      "them           \t0\n",
      "were           \t0\n",
      "dolphin        \t0\n",
      "blu            \t-1\n",
      "##bber         \t1\n",
      "and            \t0\n",
      "those          \t0\n",
      "dolphin        \t0\n",
      "parts          \t0\n",
      "had            \t0\n",
      "a              \t0\n",
      "huge           \t0\n",
      "load           \t0\n",
      "of             \t0\n",
      "pc             \t-1\n",
      "##bs           \t3\n",
      "di             \t-1\n",
      "##ox           \t-1\n",
      "##ins          \t0\n",
      "and            \t0\n",
      "heavy          \t0\n",
      "metals         \t1\n",
      "and            \t0\n",
      "that           \t0\n",
      "huge           \t0\n",
      "load           \t0\n",
      "was            \t0\n",
      "passing        \t0\n",
      "into           \t0\n",
      "the            \t0\n",
      "people         \t0\n",
      "that           \t0\n",
      "ate            \t0\n",
      "this           \t0\n",
      "meat           \t1\n",
      "it             \t0\n",
      "turns          \t0\n",
      "out            \t0\n",
      "that           \t0\n",
      "a              \t0\n",
      "lot            \t0\n",
      "of             \t0\n",
      "dolphins       \t0\n",
      "are            \t0\n",
      "being          \t0\n",
      "sold           \t0\n",
      "as             \t0\n",
      "meat           \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "whale          \t0\n",
      "meat           \t0\n",
      "market         \t0\n",
      "around         \t0\n",
      "the            \t0\n",
      "world          \t1\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "a              \t0\n",
      "tragedy        \t0\n",
      "for            \t0\n",
      "those          \t0\n",
      "populations    \t3\n",
      "but            \t0\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "also           \t0\n",
      "a              \t0\n",
      "tragedy        \t0\n",
      "for            \t0\n",
      "the            \t0\n",
      "people         \t0\n",
      "eating         \t0\n",
      "them           \t0\n",
      "because        \t0\n",
      "they           \t0\n",
      "don            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "know           \t0\n",
      "that           \t0\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "toxic          \t0\n",
      "meat           \t1\n",
      "we             \t0\n",
      "had            \t0\n",
      "these          \t0\n",
      "data           \t0\n",
      "a              \t0\n",
      "few            \t0\n",
      "years          \t0\n",
      "ago            \t1\n",
      "i              \t0\n",
      "remember       \t0\n",
      "sitting        \t0\n",
      "at             \t0\n",
      "my             \t0\n",
      "desk           \t0\n",
      "being          \t0\n",
      "about          \t0\n",
      "the            \t0\n",
      "only           \t0\n",
      "person         \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "world          \t0\n",
      "who            \t0\n",
      "knew           \t0\n",
      "that           \t0\n",
      "whale          \t0\n",
      "meat           \t0\n",
      "being          \t0\n",
      "sold           \t0\n",
      "in             \t0\n",
      "these          \t0\n",
      "markets        \t0\n",
      "was            \t0\n",
      "really         \t0\n",
      "dolphin        \t0\n",
      "meat           \t3\n",
      "and            \t0\n",
      "it             \t0\n",
      "was            \t0\n",
      "toxic          \t1\n",
      "it             \t0\n",
      "had            \t0\n",
      "two            \t0\n",
      "to             \t0\n",
      "three          \t0\n",
      "to             \t-1\n",
      "-              \t-1\n",
      "400            \t0\n",
      "times          \t0\n",
      "the            \t0\n",
      "toxic          \t0\n",
      "loads          \t0\n",
      "ever           \t0\n",
      "allowed        \t0\n",
      "by             \t0\n",
      "the            \t0\n",
      "epa            \t1\n",
      "and            \t0\n",
      "i              \t0\n",
      "remember       \t0\n",
      "there          \t0\n",
      "sitting        \t0\n",
      "at             \t0\n",
      "my             \t0\n",
      "desk           \t0\n",
      "thinking       \t-1\n",
      ",              \t-1\n",
      "well           \t3\n",
      "i              \t0\n",
      "know           \t0\n",
      "this           \t1\n",
      "this           \t0\n",
      "is             \t0\n",
      "a              \t0\n",
      "great          \t0\n",
      "scientific     \t0\n",
      "discovery      \t3\n",
      "but            \t0\n",
      "it             \t0\n",
      "was            \t0\n",
      "so             \t0\n",
      "awful          \t1\n",
      "and            \t0\n",
      "for            \t0\n",
      "the            \t0\n",
      "very           \t0\n",
      "first          \t0\n",
      "time           \t0\n",
      "in             \t0\n",
      "my             \t0\n",
      "scientific     \t0\n",
      "career         \t3\n",
      "i              \t0\n",
      "broke          \t0\n",
      "scientific     \t0\n",
      "protocol       \t3\n",
      "which          \t0\n",
      "is             \t0\n",
      "that           \t0\n",
      "you            \t0\n",
      "take           \t0\n",
      "the            \t0\n",
      "data           \t0\n",
      "and            \t0\n",
      "publish        \t0\n",
      "them           \t0\n",
      "in             \t0\n",
      "scientific     \t0\n",
      "journals       \t0\n",
      "and            \t0\n",
      "then           \t0\n",
      "begin          \t0\n",
      "to             \t0\n",
      "talk           \t0\n",
      "about          \t0\n",
      "them           \t1\n",
      "we             \t0\n",
      "sent           \t0\n",
      "a              \t0\n",
      "very           \t0\n",
      "polite         \t0\n",
      "letter         \t0\n",
      "to             \t0\n",
      "the            \t0\n",
      "minister       \t0\n",
      "of             \t0\n",
      "health         \t0\n",
      "in             \t0\n",
      "japan          \t0\n",
      "and            \t0\n",
      "simply         \t0\n",
      "pointed        \t0\n",
      "out            \t0\n",
      "that           \t0\n",
      "this           \t0\n",
      "is             \t0\n",
      "an             \t0\n",
      "into           \t-1\n",
      "##ler          \t-1\n",
      "##able         \t0\n",
      "situation      \t3\n",
      "not            \t0\n",
      "for            \t0\n",
      "us             \t3\n",
      "but            \t0\n",
      "for            \t0\n",
      "the            \t0\n",
      "people         \t0\n",
      "of             \t0\n",
      "japan          \t0\n",
      "because        \t0\n",
      "mothers        \t0\n",
      "who            \t0\n",
      "may            \t0\n",
      "be             \t0\n",
      "breast         \t-1\n",
      "##fe           \t-1\n",
      "##eding        \t3\n",
      "who            \t0\n",
      "may            \t0\n",
      "have           \t0\n",
      "young          \t0\n",
      "children       \t3\n",
      "would          \t0\n",
      "be             \t0\n",
      "buying         \t0\n",
      "something      \t0\n",
      "that           \t0\n",
      "they           \t0\n",
      "thought        \t0\n",
      "was            \t0\n",
      "healthy        \t3\n",
      "but            \t0\n",
      "it             \t0\n",
      "was            \t0\n",
      "really         \t0\n",
      "toxic          \t1\n",
      "that           \t0\n",
      "led            \t0\n",
      "to             \t0\n",
      "a              \t0\n",
      "whole          \t0\n",
      "series         \t0\n",
      "of             \t0\n",
      "other          \t0\n",
      "campaigns      \t0\n",
      "in             \t0\n",
      "japan          \t3\n",
      "and            \t0\n",
      "i              \t-1\n",
      "'              \t-1\n",
      "m              \t0\n",
      "really         \t0\n",
      "proud          \t0\n",
      "to             \t0\n",
      "say            \t0\n",
      "that           \t0\n",
      "at             \t0\n",
      "this           \t0\n",
      "point          \t3\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "very           \t0\n",
      "difficult      \t0\n",
      "to             \t0\n",
      "buy            \t0\n",
      "anything       \t0\n",
      "in             \t0\n",
      "japan          \t0\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "labeled        \t0\n",
      "incorrectly    \t3\n",
      "even           \t0\n",
      "though         \t0\n",
      "they           \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "still          \t0\n",
      "selling        \t0\n",
      "whale          \t0\n",
      "meat           \t3\n",
      "which          \t0\n",
      "i              \t0\n",
      "believe        \t0\n",
      "they           \t0\n",
      "shouldn        \t-1\n",
      "'              \t-1\n",
      "t              \t1\n",
      "but            \t0\n",
      "at             \t0\n",
      "least          \t0\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "labeled        \t0\n",
      "correctly      \t3\n",
      "and            \t0\n",
      "you            \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "no             \t0\n",
      "longer         \t0\n",
      "going          \t0\n",
      "to             \t0\n",
      "be             \t0\n",
      "buying         \t0\n",
      "toxic          \t0\n",
      "dolphin        \t0\n",
      "meat           \t0\n",
      "instead        \t1\n",
      "it             \t0\n",
      "isn            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "just           \t0\n",
      "there          \t0\n",
      "that           \t0\n",
      "this           \t0\n",
      "happens        \t3\n",
      "but            \t0\n",
      "in             \t0\n",
      "a              \t0\n",
      "natural        \t0\n",
      "diet           \t0\n",
      "of             \t0\n",
      "some           \t0\n",
      "communities    \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "canadian       \t0\n",
      "arctic         \t0\n",
      "and            \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "united         \t0\n",
      "states         \t0\n",
      "and            \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "european       \t0\n",
      "arctic         \t3\n",
      "a              \t0\n",
      "natural        \t0\n",
      "diet           \t0\n",
      "of             \t0\n",
      "seals          \t0\n",
      "and            \t0\n",
      "whales         \t0\n",
      "leads          \t0\n",
      "to             \t0\n",
      "an             \t0\n",
      "accumulation   \t0\n",
      "of             \t0\n",
      "pc             \t-1\n",
      "##bs           \t0\n",
      "that           \t0\n",
      "have           \t0\n",
      "gathered       \t0\n",
      "up             \t0\n",
      "from           \t0\n",
      "all            \t0\n",
      "parts          \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "world          \t0\n",
      "and            \t0\n",
      "ended          \t0\n",
      "up             \t0\n",
      "in             \t0\n",
      "these          \t0\n",
      "women          \t1\n",
      "these          \t0\n",
      "women          \t0\n",
      "have           \t0\n",
      "toxic          \t0\n",
      "breast         \t0\n",
      "milk           \t1\n",
      "they           \t0\n",
      "cannot         \t0\n",
      "feed           \t0\n",
      "their          \t0\n",
      "offspring      \t3\n",
      "their          \t0\n",
      "children       \t3\n",
      "their          \t0\n",
      "breast         \t0\n",
      "milk           \t0\n",
      "because        \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "accumulation   \t0\n",
      "of             \t0\n",
      "these          \t0\n",
      "toxin          \t-1\n",
      "##s            \t0\n",
      "in             \t0\n",
      "their          \t0\n",
      "food           \t0\n",
      "chain          \t3\n",
      "in             \t0\n",
      "their          \t0\n",
      "part           \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "world          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "ocean          \t0\n",
      "pyramid        \t1\n",
      "that           \t0\n",
      "means          \t0\n",
      "their          \t0\n",
      "immune         \t0\n",
      "systems        \t0\n",
      "are            \t0\n",
      "compromised    \t1\n",
      "it             \t0\n",
      "means          \t0\n",
      "that           \t0\n",
      "their          \t0\n",
      "children       \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "development    \t0\n",
      "can            \t0\n",
      "be             \t0\n",
      "compromised    \t1\n",
      "and            \t0\n",
      "the            \t0\n",
      "world          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "attention      \t0\n",
      "on             \t0\n",
      "this           \t0\n",
      "over           \t0\n",
      "the            \t0\n",
      "last           \t0\n",
      "decade         \t0\n",
      "has            \t0\n",
      "reduced        \t0\n",
      "the            \t0\n",
      "problem        \t0\n",
      "for            \t0\n",
      "these          \t0\n",
      "women          \t3\n",
      "not            \t0\n",
      "by             \t0\n",
      "changing       \t0\n",
      "the            \t0\n",
      "pyramid        \t3\n",
      "but            \t0\n",
      "by             \t0\n",
      "changing       \t0\n",
      "what           \t0\n",
      "they           \t0\n",
      "particularly   \t0\n",
      "eat            \t0\n",
      "out            \t0\n",
      "of             \t0\n",
      "it             \t1\n",
      "we             \t-1\n",
      "'              \t-1\n",
      "ve             \t0\n",
      "taken          \t0\n",
      "them           \t0\n",
      "out            \t0\n",
      "of             \t0\n",
      "their          \t0\n",
      "natural        \t0\n",
      "pyramid        \t0\n",
      "in             \t0\n",
      "order          \t0\n",
      "to             \t0\n",
      "solve          \t0\n",
      "this           \t0\n",
      "problem        \t1\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "a              \t0\n",
      "good           \t0\n",
      "thing          \t0\n",
      "for            \t0\n",
      "this           \t0\n",
      "particular     \t0\n",
      "acute          \t0\n",
      "problem        \t3\n",
      "but            \t0\n",
      "it             \t0\n",
      "does           \t0\n",
      "nothing        \t0\n",
      "to             \t0\n",
      "solve          \t0\n",
      "the            \t0\n",
      "pyramid        \t0\n",
      "problem        \t1\n",
      "there          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "other          \t0\n",
      "ways           \t0\n",
      "of             \t0\n",
      "breaking       \t0\n",
      "the            \t0\n",
      "pyramid        \t1\n",
      "the            \t0\n",
      "pyramid        \t3\n",
      "if             \t0\n",
      "we             \t0\n",
      "jam            \t0\n",
      "things         \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "bottom         \t3\n",
      "can            \t0\n",
      "get            \t0\n",
      "backed         \t0\n",
      "up             \t0\n",
      "like           \t0\n",
      "a              \t0\n",
      "sewer          \t0\n",
      "line           \t0\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "cl             \t-1\n",
      "##og           \t-1\n",
      "##ged          \t1\n",
      "and            \t0\n",
      "if             \t0\n",
      "we             \t0\n",
      "jam            \t0\n",
      "nutrients      \t3\n",
      "sewage         \t3\n",
      "fe             \t-1\n",
      "##rti          \t-1\n",
      "##lizer        \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "base           \t0\n",
      "of             \t0\n",
      "that           \t0\n",
      "food           \t0\n",
      "pyramid        \t3\n",
      "it             \t0\n",
      "can            \t0\n",
      "back           \t0\n",
      "up             \t0\n",
      "all            \t0\n",
      "through        \t0\n",
      "it             \t1\n",
      "we             \t0\n",
      "end            \t0\n",
      "up             \t0\n",
      "with           \t0\n",
      "things         \t0\n",
      "we             \t-1\n",
      "'              \t-1\n",
      "ve             \t0\n",
      "heard          \t0\n",
      "about          \t0\n",
      "before         \t3\n",
      "red            \t0\n",
      "tides          \t3\n",
      "for            \t0\n",
      "example        \t3\n",
      "which          \t0\n",
      "are            \t0\n",
      "blooms         \t0\n",
      "of             \t0\n",
      "toxic          \t0\n",
      "algae          \t0\n",
      "floating       \t0\n",
      "through        \t0\n",
      "the            \t0\n",
      "oceans         \t0\n",
      "causing        \t0\n",
      "neurological   \t0\n",
      "damage         \t1\n",
      "we             \t0\n",
      "can            \t0\n",
      "also           \t0\n",
      "see            \t0\n",
      "blooms         \t0\n",
      "of             \t0\n",
      "bacteria       \t3\n",
      "blooms         \t0\n",
      "of             \t0\n",
      "viruses        \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "ocean          \t1\n",
      "these          \t0\n",
      "are            \t0\n",
      "two            \t0\n",
      "shots          \t0\n",
      "of             \t0\n",
      "a              \t0\n",
      "red            \t0\n",
      "tide           \t0\n",
      "coming         \t0\n",
      "on             \t0\n",
      "shore          \t0\n",
      "here           \t0\n",
      "and            \t0\n",
      "a              \t0\n",
      "bacteria       \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "genus          \t0\n",
      "vi             \t-1\n",
      "##bri          \t-1\n",
      "##o            \t3\n",
      "which          \t0\n",
      "includes       \t0\n",
      "the            \t0\n",
      "genus          \t0\n",
      "that           \t0\n",
      "has            \t0\n",
      "cholera        \t0\n",
      "in             \t0\n",
      "it             \t1\n",
      "how            \t0\n",
      "many           \t0\n",
      "people         \t0\n",
      "have           \t0\n",
      "seen           \t0\n",
      "a              \t-1\n",
      ",              \t-1\n",
      "beach          \t0\n",
      "closed         \t3\n",
      "sign           \t2\n",
      "why            \t0\n",
      "does           \t0\n",
      "that           \t0\n",
      "happen         \t2\n",
      "it             \t0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happens        \t0\n",
      "because        \t0\n",
      "we             \t0\n",
      "have           \t0\n",
      "jammed         \t0\n",
      "so             \t0\n",
      "much           \t0\n",
      "into           \t0\n",
      "the            \t0\n",
      "base           \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "natural        \t0\n",
      "ocean          \t0\n",
      "pyramid        \t0\n",
      "that           \t0\n",
      "these          \t0\n",
      "bacteria       \t0\n",
      "cl             \t-1\n",
      "##og           \t0\n",
      "it             \t0\n",
      "up             \t0\n",
      "and            \t0\n",
      "over           \t-1\n",
      "##fi           \t-1\n",
      "##ll           \t0\n",
      "onto           \t0\n",
      "our            \t0\n",
      "beaches        \t1\n",
      "often          \t0\n",
      "what           \t0\n",
      "jam            \t-1\n",
      "##s            \t0\n",
      "us             \t0\n",
      "up             \t0\n",
      "is             \t0\n",
      "sewage         \t1\n",
      "now            \t0\n",
      "how            \t0\n",
      "many           \t0\n",
      "of             \t0\n",
      "you            \t0\n",
      "have           \t0\n",
      "ever           \t0\n",
      "gone           \t0\n",
      "to             \t0\n",
      "a              \t0\n",
      "state          \t0\n",
      "park           \t0\n",
      "or             \t0\n",
      "a              \t0\n",
      "national       \t0\n",
      "park           \t0\n",
      "where          \t0\n",
      "you            \t0\n",
      "had            \t0\n",
      "a              \t0\n",
      "big            \t0\n",
      "sign           \t0\n",
      "at             \t0\n",
      "the            \t0\n",
      "front          \t0\n",
      "saying         \t-1\n",
      ",              \t-1\n",
      "closed         \t0\n",
      "because        \t0\n",
      "human          \t0\n",
      "sewage         \t0\n",
      "is             \t0\n",
      "so             \t0\n",
      "far            \t0\n",
      "over           \t0\n",
      "this           \t0\n",
      "park           \t0\n",
      "that           \t0\n",
      "you            \t0\n",
      "can            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "use            \t0\n",
      "it             \t3\n",
      "not            \t0\n",
      "very           \t0\n",
      "often          \t1\n",
      "we             \t0\n",
      "wouldn         \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "tolerate       \t0\n",
      "that           \t1\n",
      "we             \t0\n",
      "wouldn         \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "tolerate       \t0\n",
      "our            \t0\n",
      "parks          \t0\n",
      "being          \t0\n",
      "swamp          \t-1\n",
      "##ed           \t0\n",
      "by             \t0\n",
      "human          \t0\n",
      "sewage         \t3\n",
      "but            \t0\n",
      "beaches        \t0\n",
      "are            \t0\n",
      "closed         \t0\n",
      "a              \t0\n",
      "lot            \t0\n",
      "in             \t0\n",
      "our            \t0\n",
      "country        \t1\n",
      "they           \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "closed         \t0\n",
      "more           \t0\n",
      "and            \t0\n",
      "more           \t0\n",
      "and            \t0\n",
      "more           \t0\n",
      "all            \t0\n",
      "around         \t0\n",
      "the            \t0\n",
      "world          \t0\n",
      "for            \t0\n",
      "the            \t0\n",
      "same           \t0\n",
      "reason         \t3\n",
      "and            \t0\n",
      "i              \t0\n",
      "believe        \t0\n",
      "we             \t0\n",
      "shouldn        \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "tolerate       \t0\n",
      "that           \t0\n",
      "either         \t1\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "not            \t0\n",
      "just           \t0\n",
      "a              \t0\n",
      "question       \t0\n",
      "of             \t0\n",
      "clean          \t-1\n",
      "##liness       \t1\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "also           \t0\n",
      "a              \t0\n",
      "question       \t0\n",
      "of             \t0\n",
      "how            \t0\n",
      "those          \t0\n",
      "organisms      \t0\n",
      "then           \t0\n",
      "turn           \t0\n",
      "into           \t0\n",
      "human          \t0\n",
      "disease        \t1\n",
      "these          \t0\n",
      "vi             \t-1\n",
      "##bri          \t-1\n",
      "##os           \t3\n",
      "these          \t0\n",
      "bacteria       \t3\n",
      "can            \t0\n",
      "actually       \t0\n",
      "in             \t-1\n",
      "##fect         \t0\n",
      "people         \t1\n",
      "they           \t0\n",
      "can            \t0\n",
      "go             \t0\n",
      "into           \t0\n",
      "your           \t0\n",
      "skin           \t0\n",
      "and            \t0\n",
      "create         \t0\n",
      "skin           \t0\n",
      "infections     \t1\n",
      "this           \t0\n",
      "is             \t0\n",
      "a              \t0\n",
      "graph          \t0\n",
      "from           \t0\n",
      "no             \t-1\n",
      "##aa           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "ocean          \t0\n",
      "and            \t0\n",
      "human          \t0\n",
      "health         \t0\n",
      "initiative     \t3\n",
      "showing        \t0\n",
      "the            \t0\n",
      "rise           \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "infections     \t0\n",
      "by             \t0\n",
      "vi             \t-1\n",
      "##bri          \t-1\n",
      "##o            \t0\n",
      "in             \t0\n",
      "people         \t0\n",
      "over           \t0\n",
      "the            \t0\n",
      "last           \t0\n",
      "few            \t0\n",
      "years          \t1\n",
      "surfer         \t-1\n",
      "##s            \t3\n",
      "for            \t0\n",
      "example        \t3\n",
      "know           \t0\n",
      "this           \t0\n",
      "incredibly     \t1\n",
      "and            \t0\n",
      "if             \t0\n",
      "you            \t0\n",
      "can            \t0\n",
      "see            \t0\n",
      "on             \t0\n",
      "some           \t0\n",
      "surfing        \t0\n",
      "sites          \t3\n",
      "in             \t0\n",
      "fact           \t3\n",
      "not            \t0\n",
      "only           \t0\n",
      "do             \t0\n",
      "you            \t0\n",
      "see            \t0\n",
      "what           \t0\n",
      "the            \t0\n",
      "waves          \t0\n",
      "are            \t0\n",
      "like           \t0\n",
      "or             \t0\n",
      "what           \t0\n",
      "the            \t0\n",
      "weather        \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "like           \t3\n",
      "but            \t0\n",
      "on             \t0\n",
      "some           \t0\n",
      "surf           \t0\n",
      "rider          \t0\n",
      "sites          \t3\n",
      "you            \t0\n",
      "see            \t0\n",
      "a              \t0\n",
      "little         \t0\n",
      "flashing       \t0\n",
      "po             \t-1\n",
      "##o            \t0\n",
      "alert          \t1\n",
      "that           \t0\n",
      "means          \t0\n",
      "that           \t0\n",
      "the            \t0\n",
      "beach          \t0\n",
      "might          \t0\n",
      "have           \t0\n",
      "great          \t0\n",
      "waves          \t3\n",
      "but            \t0\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "a              \t0\n",
      "dangerous      \t0\n",
      "place          \t0\n",
      "for            \t0\n",
      "surfer         \t-1\n",
      "##s            \t0\n",
      "to             \t0\n",
      "be             \t0\n",
      "because        \t0\n",
      "they           \t0\n",
      "can            \t0\n",
      "carry          \t0\n",
      "with           \t0\n",
      "them           \t3\n",
      "even           \t0\n",
      "after          \t0\n",
      "a              \t0\n",
      "great          \t0\n",
      "day            \t0\n",
      "of             \t0\n",
      "surfing        \t3\n",
      "this           \t0\n",
      "legacy         \t0\n",
      "of             \t0\n",
      "an             \t0\n",
      "infection      \t0\n",
      "that           \t0\n",
      "might          \t0\n",
      "take           \t0\n",
      "a              \t0\n",
      "very           \t0\n",
      "long           \t0\n",
      "time           \t0\n",
      "to             \t0\n",
      "solve          \t1\n",
      "some           \t0\n",
      "of             \t0\n",
      "these          \t0\n",
      "infections     \t0\n",
      "are            \t0\n",
      "actually       \t0\n",
      "carrying       \t0\n",
      "anti           \t-1\n",
      "##biotic       \t0\n",
      "resistance     \t0\n",
      "genes          \t0\n",
      "now            \t3\n",
      "and            \t0\n",
      "that           \t0\n",
      "makes          \t0\n",
      "them           \t0\n",
      "even           \t0\n",
      "more           \t0\n",
      "difficult      \t1\n",
      "these          \t0\n",
      "same           \t0\n",
      "infections     \t0\n",
      "create         \t0\n",
      "harmful        \t0\n",
      "al             \t-1\n",
      "##gal          \t0\n",
      "blooms         \t1\n",
      "those          \t0\n",
      "blooms         \t0\n",
      "are            \t0\n",
      "generating     \t0\n",
      "other          \t0\n",
      "kinds          \t0\n",
      "of             \t0\n",
      "chemicals      \t1\n",
      "this           \t0\n",
      "is             \t0\n",
      "just           \t0\n",
      "a              \t0\n",
      "simple         \t0\n",
      "list           \t0\n",
      "of             \t0\n",
      "some           \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "types          \t0\n",
      "of             \t0\n",
      "poison         \t-1\n",
      "##s            \t0\n",
      "that           \t0\n",
      "come           \t0\n",
      "out            \t0\n",
      "of             \t0\n",
      "these          \t0\n",
      "harmful        \t0\n",
      "al             \t-1\n",
      "##gal          \t0\n",
      "blooms         \t3\n",
      "shell          \t-1\n",
      "##fish         \t0\n",
      "poisoning      \t-1\n",
      ",              \t-1\n",
      "fish           \t0\n",
      "ci             \t-1\n",
      "##gua          \t-1\n",
      "##tera         \t3\n",
      "dia            \t-1\n",
      "##rr           \t-1\n",
      "##hei          \t-1\n",
      "##c            \t0\n",
      "shell          \t-1\n",
      "##fish         \t0\n",
      "poisoning      \t3\n",
      "you            \t0\n",
      "don            \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "want           \t0\n",
      "to             \t0\n",
      "know           \t0\n",
      "about          \t0\n",
      "that           \t3\n",
      "ne             \t-1\n",
      "##uro          \t-1\n",
      "##to           \t-1\n",
      "##xi           \t-1\n",
      "##c            \t0\n",
      "shell          \t-1\n",
      "##fish         \t0\n",
      "poisoning      \t3\n",
      "para           \t-1\n",
      "##ly           \t-1\n",
      "##tic          \t0\n",
      "shell          \t-1\n",
      "##fish         \t0\n",
      "poisoning      \t1\n",
      "these          \t0\n",
      "are            \t0\n",
      "things         \t0\n",
      "that           \t0\n",
      "are            \t0\n",
      "getting        \t0\n",
      "into           \t0\n",
      "our            \t0\n",
      "food           \t0\n",
      "chain          \t0\n",
      "because        \t0\n",
      "of             \t0\n",
      "these          \t0\n",
      "blooms         \t1\n",
      "rita           \t0\n",
      "cal            \t-1\n",
      "##well         \t0\n",
      "very           \t0\n",
      "famously       \t0\n",
      "traced         \t0\n",
      "a              \t0\n",
      "very           \t0\n",
      "interesting    \t0\n",
      "story          \t0\n",
      "of             \t0\n",
      "cholera        \t0\n",
      "into           \t0\n",
      "human          \t0\n",
      "communities    \t3\n",
      "brought        \t0\n",
      "there          \t3\n",
      "not            \t0\n",
      "by             \t0\n",
      "a              \t0\n",
      "normal         \t0\n",
      "human          \t0\n",
      "vector         \t3\n",
      "but            \t0\n",
      "by             \t0\n",
      "a              \t0\n",
      "marine         \t0\n",
      "vector         \t3\n",
      "this           \t0\n",
      "cope           \t-1\n",
      "##pod          \t1\n",
      "cope           \t-1\n",
      "##pods         \t0\n",
      "are            \t0\n",
      "small          \t0\n",
      "crust          \t-1\n",
      "##ace          \t-1\n",
      "##ans          \t1\n",
      "they           \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "a              \t0\n",
      "tiny           \t0\n",
      "fraction       \t0\n",
      "of             \t0\n",
      "an             \t0\n",
      "inch           \t0\n",
      "long           \t3\n",
      "and            \t0\n",
      "they           \t0\n",
      "can            \t0\n",
      "carry          \t0\n",
      "on             \t0\n",
      "their          \t0\n",
      "little         \t0\n",
      "legs           \t0\n",
      "some           \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "cholera        \t0\n",
      "bacteria       \t0\n",
      "that           \t0\n",
      "then           \t0\n",
      "leads          \t0\n",
      "to             \t0\n",
      "human          \t0\n",
      "disease        \t1\n",
      "that           \t0\n",
      "has            \t0\n",
      "sparked        \t0\n",
      "cholera        \t0\n",
      "epidemic       \t-1\n",
      "##s            \t0\n",
      "in             \t0\n",
      "ports          \t0\n",
      "along          \t0\n",
      "the            \t0\n",
      "world          \t0\n",
      "and            \t0\n",
      "has            \t0\n",
      "led            \t0\n",
      "to             \t0\n",
      "increased      \t0\n",
      "concentration  \t0\n",
      "on             \t0\n",
      "trying         \t0\n",
      "to             \t0\n",
      "make           \t0\n",
      "sure           \t0\n",
      "shipping       \t0\n",
      "doesn          \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "move           \t0\n",
      "these          \t0\n",
      "vectors        \t0\n",
      "of             \t0\n",
      "cholera        \t0\n",
      "around         \t0\n",
      "the            \t0\n",
      "world          \t1\n",
      "so             \t0\n",
      "what           \t0\n",
      "do             \t0\n",
      "you            \t0\n",
      "do             \t2\n",
      "we             \t0\n",
      "have           \t0\n",
      "major          \t0\n",
      "problems       \t0\n",
      "in             \t0\n",
      "disrupted      \t0\n",
      "ecosystem      \t0\n",
      "flow           \t0\n",
      "that           \t0\n",
      "the            \t0\n",
      "pyramid        \t0\n",
      "may            \t0\n",
      "not            \t0\n",
      "be             \t0\n",
      "working        \t0\n",
      "so             \t0\n",
      "well           \t3\n",
      "that           \t0\n",
      "the            \t0\n",
      "flow           \t0\n",
      "from           \t0\n",
      "the            \t0\n",
      "base           \t0\n",
      "up             \t0\n",
      "into           \t0\n",
      "it             \t0\n",
      "is             \t0\n",
      "being          \t0\n",
      "blocked        \t0\n",
      "and            \t0\n",
      "cl             \t-1\n",
      "##og           \t-1\n",
      "##ged          \t1\n",
      "what           \t0\n",
      "do             \t0\n",
      "you            \t0\n",
      "do             \t0\n",
      "when           \t0\n",
      "you            \t0\n",
      "have           \t0\n",
      "this           \t0\n",
      "sort           \t0\n",
      "of             \t0\n",
      "disrupted      \t0\n",
      "flow           \t2\n",
      "well           \t3\n",
      "there          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "a              \t0\n",
      "bunch          \t0\n",
      "of             \t0\n",
      "things         \t0\n",
      "you            \t0\n",
      "could          \t0\n",
      "do             \t1\n",
      "you            \t0\n",
      "could          \t0\n",
      "call           \t0\n",
      "joe            \t0\n",
      "the            \t0\n",
      "plum           \t-1\n",
      "##ber          \t3\n",
      "for            \t0\n",
      "example        \t1\n",
      "and            \t0\n",
      "he             \t0\n",
      "could          \t0\n",
      "come           \t0\n",
      "in             \t0\n",
      "and            \t0\n",
      "fix            \t0\n",
      "the            \t0\n",
      "flow           \t1\n",
      "but            \t0\n",
      "in             \t0\n",
      "fact           \t3\n",
      "if             \t0\n",
      "you            \t0\n",
      "look           \t0\n",
      "around         \t0\n",
      "the            \t0\n",
      "world          \t3\n",
      "not            \t0\n",
      "only           \t0\n",
      "are            \t0\n",
      "there          \t0\n",
      "hope           \t0\n",
      "spots          \t0\n",
      "for            \t0\n",
      "where          \t0\n",
      "we             \t0\n",
      "may            \t0\n",
      "be             \t0\n",
      "able           \t0\n",
      "to             \t0\n",
      "fix            \t0\n",
      "problems       \t3\n",
      "there          \t0\n",
      "have           \t0\n",
      "been           \t0\n",
      "places         \t0\n",
      "where          \t0\n",
      "problems       \t0\n",
      "have           \t0\n",
      "been           \t0\n",
      "fixed          \t3\n",
      "where          \t0\n",
      "people         \t0\n",
      "have           \t0\n",
      "come           \t0\n",
      "to             \t0\n",
      "grips          \t0\n",
      "with           \t0\n",
      "these          \t0\n",
      "issues         \t0\n",
      "and            \t0\n",
      "begun          \t0\n",
      "to             \t0\n",
      "turn           \t0\n",
      "them           \t0\n",
      "around         \t1\n",
      "monterey       \t0\n",
      "is             \t0\n",
      "one            \t0\n",
      "of             \t0\n",
      "those          \t1\n",
      "i              \t0\n",
      "started        \t0\n",
      "out            \t0\n",
      "showing        \t0\n",
      "how            \t0\n",
      "much           \t0\n",
      "we             \t0\n",
      "had            \t0\n",
      "distressed     \t0\n",
      "the            \t0\n",
      "monterey       \t0\n",
      "bay            \t0\n",
      "ecosystem      \t0\n",
      "with           \t0\n",
      "pollution      \t0\n",
      "and            \t0\n",
      "the            \t0\n",
      "canning        \t0\n",
      "industry       \t0\n",
      "and            \t0\n",
      "all            \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "attendant      \t0\n",
      "problems       \t1\n",
      "in             \t0\n",
      "1932           \t3\n",
      "that           \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "the            \t0\n",
      "picture        \t1\n",
      "in             \t0\n",
      "2009           \t3\n",
      "the            \t0\n",
      "picture        \t0\n",
      "is             \t0\n",
      "dramatically   \t0\n",
      "different      \t1\n",
      "the            \t0\n",
      "can            \t-1\n",
      "##ner          \t-1\n",
      "##ies          \t0\n",
      "are            \t0\n",
      "gone           \t1\n",
      "the            \t0\n",
      "pollution      \t0\n",
      "has            \t0\n",
      "aba            \t-1\n",
      "##ted          \t1\n",
      "but            \t0\n",
      "there          \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "a              \t0\n",
      "greater        \t0\n",
      "sense          \t0\n",
      "here           \t0\n",
      "that           \t0\n",
      "what           \t0\n",
      "the            \t0\n",
      "individual     \t0\n",
      "communities    \t0\n",
      "need           \t0\n",
      "is             \t0\n",
      "working        \t0\n",
      "ecosystems     \t1\n",
      "they           \t0\n",
      "need           \t0\n",
      "a              \t0\n",
      "functioning    \t0\n",
      "pyramid        \t0\n",
      "from           \t0\n",
      "the            \t0\n",
      "base           \t0\n",
      "all            \t0\n",
      "the            \t0\n",
      "way            \t0\n",
      "to             \t0\n",
      "the            \t0\n",
      "top            \t1\n",
      "and            \t0\n",
      "that           \t0\n",
      "pyramid        \t0\n",
      "in             \t0\n",
      "monterey       \t3\n",
      "right          \t0\n",
      "now            \t3\n",
      "because        \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "efforts        \t0\n",
      "of             \t0\n",
      "a              \t0\n",
      "lot            \t0\n",
      "of             \t0\n",
      "different      \t0\n",
      "people         \t3\n",
      "is             \t0\n",
      "functioning    \t0\n",
      "better         \t0\n",
      "than           \t0\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "ever           \t0\n",
      "functioned     \t0\n",
      "for            \t0\n",
      "the            \t0\n",
      "last           \t0\n",
      "150            \t0\n",
      "years          \t1\n",
      "it             \t0\n",
      "didn           \t-1\n",
      "'              \t-1\n",
      "t              \t0\n",
      "happen         \t0\n",
      "accidentally   \t1\n",
      "it             \t0\n",
      "happened       \t0\n",
      "because        \t0\n",
      "many           \t0\n",
      "people         \t0\n",
      "put            \t0\n",
      "their          \t0\n",
      "time           \t0\n",
      "and            \t0\n",
      "effort         \t0\n",
      "and            \t0\n",
      "their          \t0\n",
      "pioneering     \t0\n",
      "spirit         \t0\n",
      "into           \t0\n",
      "this           \t1\n",
      "on             \t0\n",
      "the            \t0\n",
      "left           \t0\n",
      "there          \t3\n",
      "julia          \t0\n",
      "platt          \t3\n",
      "the            \t0\n",
      "mayor          \t0\n",
      "of             \t0\n",
      "my             \t0\n",
      "little         \t0\n",
      "hometown       \t0\n",
      "in             \t0\n",
      "pacific        \t0\n",
      "grove          \t1\n",
      "at             \t0\n",
      "74             \t0\n",
      "years          \t0\n",
      "old            \t3\n",
      "became         \t0\n",
      "mayor          \t0\n",
      "because        \t0\n",
      "something      \t0\n",
      "had            \t0\n",
      "to             \t0\n",
      "be             \t0\n",
      "done           \t0\n",
      "to             \t0\n",
      "protect        \t0\n",
      "the            \t0\n",
      "ocean          \t1\n",
      "in             \t0\n",
      "1931           \t3\n",
      "she            \t0\n",
      "produced       \t0\n",
      "california     \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "first          \t0\n",
      "community      \t0\n",
      "based          \t0\n",
      "marine         \t0\n",
      "protected      \t0\n",
      "area           \t3\n",
      "right          \t0\n",
      "next           \t0\n",
      "to             \t0\n",
      "the            \t0\n",
      "biggest        \t0\n",
      "poll           \t-1\n",
      "##uting        \t0\n",
      "can            \t-1\n",
      "##nery         \t3\n",
      "because        \t0\n",
      "julia          \t0\n",
      "knew           \t0\n",
      "that           \t0\n",
      "when           \t0\n",
      "the            \t0\n",
      "can            \t-1\n",
      "##ner          \t-1\n",
      "##ies          \t0\n",
      "eventually     \t0\n",
      "were           \t0\n",
      "gone           \t3\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "needed         \t0\n",
      "a              \t0\n",
      "place          \t0\n",
      "to             \t0\n",
      "grow           \t0\n",
      "from           \t3\n",
      "that           \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "needed         \t0\n",
      "a              \t0\n",
      "place          \t0\n",
      "to             \t0\n",
      "spark          \t0\n",
      "a              \t0\n",
      "seed           \t3\n",
      "and            \t0\n",
      "she            \t0\n",
      "wanted         \t0\n",
      "to             \t0\n",
      "provide        \t0\n",
      "that           \t0\n",
      "seed           \t1\n",
      "other          \t0\n",
      "people         \t3\n",
      "like           \t0\n",
      "david          \t0\n",
      "packard        \t0\n",
      "and            \t0\n",
      "julie          \t0\n",
      "packard        \t3\n",
      "who            \t0\n",
      "were           \t0\n",
      "instrumental   \t0\n",
      "in             \t0\n",
      "producing      \t0\n",
      "the            \t0\n",
      "monterey       \t0\n",
      "bay            \t0\n",
      "aquarium       \t0\n",
      "to             \t0\n",
      "lock           \t0\n",
      "into           \t0\n",
      "people         \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "notion         \t0\n",
      "that           \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "and            \t0\n",
      "the            \t0\n",
      "health         \t0\n",
      "of             \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "ecosystem      \t0\n",
      "were           \t0\n",
      "just           \t0\n",
      "as             \t0\n",
      "important      \t0\n",
      "to             \t0\n",
      "the            \t0\n",
      "economy        \t0\n",
      "of             \t0\n",
      "this           \t0\n",
      "area           \t0\n",
      "as             \t0\n",
      "eating         \t0\n",
      "the            \t0\n",
      "ecosystem      \t0\n",
      "would          \t0\n",
      "be             \t1\n",
      "that           \t0\n",
      "change         \t0\n",
      "in             \t0\n",
      "thinking       \t0\n",
      "has            \t0\n",
      "led            \t0\n",
      "to             \t0\n",
      "a              \t0\n",
      "dramatic       \t0\n",
      "shift          \t3\n",
      "not            \t0\n",
      "only           \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "fortunes       \t0\n",
      "of             \t0\n",
      "monterey       \t0\n",
      "bay            \t3\n",
      "but            \t0\n",
      "other          \t0\n",
      "places         \t0\n",
      "around         \t0\n",
      "the            \t0\n",
      "world          \t1\n",
      "well           \t3\n",
      "i              \t0\n",
      "want           \t0\n",
      "to             \t0\n",
      "leave          \t0\n",
      "you            \t0\n",
      "with           \t0\n",
      "the            \t0\n",
      "thought        \t0\n",
      "that           \t0\n",
      "what           \t0\n",
      "we             \t-1\n",
      "'              \t-1\n",
      "re             \t0\n",
      "really         \t0\n",
      "trying         \t0\n",
      "to             \t0\n",
      "do             \t0\n",
      "here           \t0\n",
      "is             \t0\n",
      "protect        \t0\n",
      "this           \t0\n",
      "ocean          \t0\n",
      "pyramid        \t3\n",
      "and            \t0\n",
      "that           \t0\n",
      "ocean          \t0\n",
      "pyramid        \t0\n",
      "connects       \t0\n",
      "to             \t0\n",
      "our            \t0\n",
      "own            \t0\n",
      "pyramid        \t0\n",
      "of             \t0\n",
      "life           \t1\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "an             \t0\n",
      "ocean          \t0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planet         \t3\n",
      "and            \t0\n",
      "we             \t0\n",
      "think          \t0\n",
      "of             \t0\n",
      "ourselves      \t0\n",
      "as             \t0\n",
      "a              \t0\n",
      "terrestrial    \t0\n",
      "species        \t3\n",
      "but            \t0\n",
      "the            \t0\n",
      "pyramid        \t0\n",
      "of             \t0\n",
      "life           \t0\n",
      "in             \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "and            \t0\n",
      "our            \t0\n",
      "own            \t0\n",
      "lives          \t0\n",
      "on             \t0\n",
      "land           \t0\n",
      "are            \t0\n",
      "intricate      \t-1\n",
      "##ly           \t0\n",
      "connected      \t1\n",
      "and            \t0\n",
      "it             \t-1\n",
      "'              \t-1\n",
      "s              \t0\n",
      "only           \t0\n",
      "through        \t0\n",
      "having         \t0\n",
      "the            \t0\n",
      "ocean          \t0\n",
      "being          \t0\n",
      "healthy        \t0\n",
      "that           \t0\n",
      "we             \t0\n",
      "can            \t0\n",
      "remain         \t0\n",
      "healthy        \t0\n",
      "ourselves      \t1\n",
      "thank          \t0\n",
      "you            \t0\n",
      "very           \t0\n",
      "much           \t1\n",
      "[SEP]          \t-1\n"
     ]
    }
   ],
   "source": [
    "# encoded_words, targets\n",
    "for te, ta in zip(encoded_texts[0][0], targets[0][0]):\n",
    "    print(f\"{tokenizer._convert_id_to_token(te):15}\\t{ta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path + model_type, exist_ok=True)\n",
    "\n",
    "for i, name in enumerate(('train', 'valid', 'test')):\n",
    "    with open(data_path + f'{model_type}/{name}_data.pkl', 'wb') as f:\n",
    "        pickle.dump((encoded_texts[i], targets[i]), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139619\t10215\t188165\t2001462\t267423\n",
      "909\t71\t1225\t15141\t1899\n",
      "1100\t46\t1120\t16208\t2072\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for ds_targets in targets:\n",
    "    c = Counter((target for t in ds_targets for target in t))\n",
    "    print('\\t'.join([str(c[i]) for i in (1,2,3,0,-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] you      \t[ P A D ] \tyou\n",
      "know           \t,         \tknow,\n",
      "i've           \t[ P A D ] \ti've\n",
      "talked         \t[ P A D ] \ttalked\n",
      "about          \t[ P A D ] \tabout\n",
      "some           \t[ P A D ] \tsome\n",
      "of             \t[ P A D ] \tof\n",
      "these          \t[ P A D ] \tthese\n",
      "projects       \t[ P A D ] \tprojects\n",
      "before         \t,         \tbefore,\n",
      "about          \t[ P A D ] \tabout\n",
      "the            \t[ P A D ] \tthe\n",
      "human          \t[ P A D ] \thuman\n",
      "genome         \t[ P A D ] \tgenome\n",
      "and            \t[ P A D ] \tand\n",
      "what           \t[ P A D ] \twhat\n",
      "that           \t[ P A D ] \tthat\n",
      "might          \t[ P A D ] \tmight\n",
      "mean           \t,         \tmean,\n",
      "and            \t[ P A D ] \tand\n",
      "discovering    \t[ P A D ] \tdiscovering\n",
      "new            \t[ P A D ] \tnew\n",
      "sets           \t[ P A D ] \tsets\n",
      "of             \t[ P A D ] \tof\n",
      "genes          \t.         \tgenes.\n",
      "we're          \t[ P A D ] \twe're\n",
      "actually       \t[ P A D ] \tactually\n",
      "starting       \t[ P A D ] \tstarting\n",
      "at             \t[ P A D ] \tat\n",
      "a              \t[ P A D ] \ta\n",
      "new            \t[ P A D ] \tnew\n",
      "point          \t,         \tpoint,\n",
      "we've          \t[ P A D ] \twe've\n",
      "been           \t[ P A D ] \tbeen\n",
      "digitizing     \t[ P A D ] \tdigitizing\n",
      "biology        \t,         \tbiology,\n",
      "and            \t[ P A D ] \tand\n",
      "now            \t[ P A D ] \tnow\n",
      "we're          \t[ P A D ] \twe're\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "go             \t[ P A D ] \tgo\n",
      "from           \t[ P A D ] \tfrom\n",
      "that           \t[ P A D ] \tthat\n",
      "digital        \t[ P A D ] \tdigital\n",
      "code           \t[ P A D ] \tcode\n",
      "into           \t[ P A D ] \tinto\n",
      "a              \t[ P A D ] \ta\n",
      "new            \t[ P A D ] \tnew\n",
      "phase          \t[ P A D ] \tphase\n",
      "of             \t[ P A D ] \tof\n",
      "biology        \t,         \tbiology,\n",
      "with           \t[ P A D ] \twith\n",
      "designing      \t[ P A D ] \tdesigning\n",
      "and            \t[ P A D ] \tand\n",
      "synthesizing   \t[ P A D ] \tsynthesizing\n",
      "life           \t.         \tlife.\n",
      "so             \t,         \tso,\n",
      "we've          \t[ P A D ] \twe've\n",
      "always         \t[ P A D ] \talways\n",
      "been           \t[ P A D ] \tbeen\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "ask            \t[ P A D ] \task\n",
      "big            \t[ P A D ] \tbig\n",
      "questions., what\t[ P A D ] \tquestions.,what\n",
      "is             \t[ P A D ] \tis\n",
      "life?          \t,         \tlife?,\n",
      "is             \t[ P A D ] \tis\n",
      "something      \t[ P A D ] \tsomething\n",
      "that           \t[ P A D ] \tthat\n",
      "i              \t[ P A D ] \ti\n",
      "think          \t[ P A D ] \tthink\n",
      "many           \t[ P A D ] \tmany\n",
      "biologists     \t[ P A D ] \tbiologists\n",
      "have           \t[ P A D ] \thave\n",
      "been           \t[ P A D ] \tbeen\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "understand     \t[ P A D ] \tunderstand\n",
      "at             \t[ P A D ] \tat\n",
      "various        \t[ P A D ] \tvarious\n",
      "levels         \t.         \tlevels.\n",
      "we've          \t[ P A D ] \twe've\n",
      "tried          \t[ P A D ] \ttried\n",
      "various        \t[ P A D ] \tvarious\n",
      "approaches     \t,         \tapproaches,\n",
      "paring         \t[ P A D ] \tparing\n",
      "it             \t[ P A D ] \tit\n",
      "down           \t[ P A D ] \tdown\n",
      "to             \t[ P A D ] \tto\n",
      "minimal        \t[ P A D ] \tminimal\n",
      "components     \t.         \tcomponents.\n",
      "we've          \t[ P A D ] \twe've\n",
      "been           \t[ P A D ] \tbeen\n",
      "digitizing     \t[ P A D ] \tdigitizing\n",
      "it             \t[ P A D ] \tit\n",
      "now            \t[ P A D ] \tnow\n",
      "for            \t[ P A D ] \tfor\n",
      "almost         \t[ P A D ] \talmost\n",
      "20             \t[ P A D ] \t20\n",
      "years          \t.         \tyears.\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "sequenced      \t[ P A D ] \tsequenced\n",
      "the            \t[ P A D ] \tthe\n",
      "human          \t[ P A D ] \thuman\n",
      "genome         \t,         \tgenome,\n",
      "it             \t[ P A D ] \tit\n",
      "was            \t[ P A D ] \twas\n",
      "going          \t[ P A D ] \tgoing\n",
      "from           \t[ P A D ] \tfrom\n",
      "the            \t[ P A D ] \tthe\n",
      "analog         \t[ P A D ] \tanalog\n",
      "world          \t[ P A D ] \tworld\n",
      "of             \t[ P A D ] \tof\n",
      "biology        \t[ P A D ] \tbiology\n",
      "into           \t[ P A D ] \tinto\n",
      "the            \t[ P A D ] \tthe\n",
      "digital        \t[ P A D ] \tdigital\n",
      "world          \t[ P A D ] \tworld\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "computer       \t.         \tcomputer.\n",
      "now            \t[ P A D ] \tnow\n",
      "we're          \t[ P A D ] \twe're\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "ask            \t,         \task,\n",
      "can            \t[ P A D ] \tcan\n",
      "we             \t[ P A D ] \twe\n",
      "regenerate     \t[ P A D ] \tregenerate\n",
      "life           \t,         \tlife,\n",
      "or             \t[ P A D ] \tor\n",
      "can            \t[ P A D ] \tcan\n",
      "we             \t[ P A D ] \twe\n",
      "create         \t[ P A D ] \tcreate\n",
      "new            \t[ P A D ] \tnew\n",
      "life           \t,         \tlife,\n",
      "out            \t[ P A D ] \tout\n",
      "of             \t[ P A D ] \tof\n",
      "this           \t[ P A D ] \tthis\n",
      "digital        \t[ P A D ] \tdigital\n",
      "universe       \t?         \tuniverse?\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "the            \t[ P A D ] \tthe\n",
      "map            \t[ P A D ] \tmap\n",
      "of             \t[ P A D ] \tof\n",
      "a              \t[ P A D ] \ta\n",
      "small          \t[ P A D ] \tsmall\n",
      "organism       \t,         \torganism,\n",
      "mycoplasma     \t[ P A D ] \tmycoplasma\n",
      "genitalium     \t,         \tgenitalium,\n",
      "that           \t[ P A D ] \tthat\n",
      "has            \t[ P A D ] \thas\n",
      "the            \t[ P A D ] \tthe\n",
      "smallest       \t[ P A D ] \tsmallest\n",
      "genome         \t[ P A D ] \tgenome\n",
      "for            \t[ P A D ] \tfor\n",
      "a              \t[ P A D ] \ta\n",
      "species        \t[ P A D ] \tspecies\n",
      "that           \t[ P A D ] \tthat\n",
      "can            \t[ P A D ] \tcan\n",
      "self           \t[ P A D ] \tself\n",
      "replicate      \t[ P A D ] \treplicate\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "laboratory     \t.         \tlaboratory.\n",
      "and            \t[ P A D ] \tand\n",
      "we've          \t[ P A D ] \twe've\n",
      "been           \t[ P A D ] \tbeen\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "just           \t[ P A D ] \tjust\n",
      "see            \t[ P A D ] \tsee\n",
      "if             \t[ P A D ] \tif\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "come           \t[ P A D ] \tcome\n",
      "up             \t[ P A D ] \tup\n",
      "with           \t[ P A D ] \twith\n",
      "an             \t[ P A D ] \tan\n",
      "even           \t[ P A D ] \teven\n",
      "smaller        \t[ P A D ] \tsmaller\n",
      "genome         \t.         \tgenome.\n",
      "we're          \t[ P A D ] \twe're\n",
      "able           \t[ P A D ] \table\n",
      "to             \t[ P A D ] \tto\n",
      "knock          \t[ P A D ] \tknock\n",
      "out            \t[ P A D ] \tout\n",
      "on             \t[ P A D ] \ton\n",
      "the            \t[ P A D ] \tthe\n",
      "order          \t[ P A D ] \torder\n",
      "of             \t[ P A D ] \tof\n",
      "a              \t[ P A D ] \ta\n",
      "hundred        \t[ P A D ] \thundred\n",
      "genes          \t[ P A D ] \tgenes\n",
      "out            \t[ P A D ] \tout\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "500            \t[ P A D ] \t500\n",
      "or             \t[ P A D ] \tor\n",
      "so             \t[ P A D ] \tso\n",
      "that           \t[ P A D ] \tthat\n",
      "are            \t[ P A D ] \tare\n",
      "here           \t.         \there.\n",
      "but            \t[ P A D ] \tbut\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "look           \t[ P A D ] \tlook\n",
      "at             \t[ P A D ] \tat\n",
      "its            \t[ P A D ] \tits\n",
      "metabolic      \t[ P A D ] \tmetabolic\n",
      "map            \t,         \tmap,\n",
      "it's           \t[ P A D ] \tit's\n",
      "relatively     \t[ P A D ] \trelatively\n",
      "simple         \t[ P A D ] \tsimple\n",
      "compared       \t[ P A D ] \tcompared\n",
      "to             \t[ P A D ] \tto\n",
      "ours           \t.         \tours.\n",
      "trust          \t[ P A D ] \ttrust\n",
      "me             \t,         \tme,\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "simple         \t.         \tsimple.\n",
      "but            \t[ P A D ] \tbut\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "look           \t[ P A D ] \tlook\n",
      "at             \t[ P A D ] \tat\n",
      "all            \t[ P A D ] \tall\n",
      "the            \t[ P A D ] \tthe\n",
      "genes          \t[ P A D ] \tgenes\n",
      "that           \t[ P A D ] \tthat\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "knock          \t[ P A D ] \tknock\n",
      "out            \t[ P A D ] \tout\n",
      "one            \t[ P A D ] \tone\n",
      "at             \t[ P A D ] \tat\n",
      "a              \t[ P A D ] \ta\n",
      "time           \t,         \ttime,\n",
      "it's           \t[ P A D ] \tit's\n",
      "very           \t[ P A D ] \tvery\n",
      "unlikely       \t[ P A D ] \tunlikely\n",
      "that           \t[ P A D ] \tthat\n",
      "this           \t[ P A D ] \tthis\n",
      "would          \t[ P A D ] \twould\n",
      "yield          \t[ P A D ] \tyield\n",
      "a              \t[ P A D ] \ta\n",
      "living         \t[ P A D ] \tliving\n",
      "cell           \t.         \tcell.\n",
      "so             \t,         \tso,\n",
      "we             \t[ P A D ] \twe\n",
      "decided        \t[ P A D ] \tdecided\n",
      "the            \t[ P A D ] \tthe\n",
      "only           \t[ P A D ] \tonly\n",
      "way            \t[ P A D ] \tway\n",
      "forward        \t[ P A D ] \tforward\n",
      "was            \t[ P A D ] \twas\n",
      "to             \t[ P A D ] \tto\n",
      "actually       \t[ P A D ] \tactually\n",
      "synthesize     \t[ P A D ] \tsynthesize\n",
      "this           \t[ P A D ] \tthis\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "could          \t[ P A D ] \tcould\n",
      "vary           \t[ P A D ] \tvary\n",
      "the            \t[ P A D ] \tthe\n",
      "components     \t[ P A D ] \tcomponents\n",
      "to             \t[ P A D ] \tto\n",
      "ask            \t[ P A D ] \task\n",
      "some           \t[ P A D ] \tsome\n",
      "of             \t[ P A D ] \tof\n",
      "these          \t[ P A D ] \tthese\n",
      "most           \t[ P A D ] \tmost\n",
      "fundamental    \t[ P A D ] \tfundamental\n",
      "questions      \t.         \tquestions.\n",
      "and            \t[ P A D ] \tand\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "started        \t[ P A D ] \tstarted\n",
      "down           \t[ P A D ] \tdown\n",
      "the            \t[ P A D ] \tthe\n",
      "road           \t[ P A D ] \troad\n",
      "of, can        \t[ P A D ] \tof,can\n",
      "we             \t[ P A D ] \twe\n",
      "synthesize     \t[ P A D ] \tsynthesize\n",
      "a              \t[ P A D ] \ta\n",
      "chromosome?    \t,         \tchromosome?,\n",
      "can            \t[ P A D ] \tcan\n",
      "chemistry      \t[ P A D ] \tchemistry\n",
      "permit         \t[ P A D ] \tpermit\n",
      "making         \t[ P A D ] \tmaking\n",
      "these          \t[ P A D ] \tthese\n",
      "really         \t[ P A D ] \treally\n",
      "large          \t[ P A D ] \tlarge\n",
      "molecules      \t[ P A D ] \tmolecules\n",
      "where          \t[ P A D ] \twhere\n",
      "we've          \t[ P A D ] \twe've\n",
      "never          \t[ P A D ] \tnever\n",
      "been           \t[ P A D ] \tbeen\n",
      "before         \t?         \tbefore?\n",
      "and            \t,         \tand,\n",
      "if             \t[ P A D ] \tif\n",
      "we             \t[ P A D ] \twe\n",
      "do             \t,         \tdo,\n",
      "can            \t[ P A D ] \tcan\n",
      "we             \t[ P A D ] \twe\n",
      "boot           \t[ P A D ] \tboot\n",
      "up             \t[ P A D ] \tup\n",
      "a              \t[ P A D ] \ta\n",
      "chromosome     \t?         \tchromosome?\n",
      "a              \t[ P A D ] \ta\n",
      "chromosome     \t,         \tchromosome,\n",
      "by             \t[ P A D ] \tby\n",
      "the            \t[ P A D ] \tthe\n",
      "way            \t,         \tway,\n",
      "is             \t[ P A D ] \tis\n",
      "just           \t[ P A D ] \tjust\n",
      "a              \t[ P A D ] \ta\n",
      "piece          \t[ P A D ] \tpiece\n",
      "of             \t[ P A D ] \tof\n",
      "inert          \t[ P A D ] \tinert\n",
      "chemical       \t[ P A D ] \tchemical\n",
      "material       \t.         \tmaterial.\n",
      "so             \t,         \tso,\n",
      "our            \t[ P A D ] \tour\n",
      "pace           \t[ P A D ] \tpace\n",
      "of             \t[ P A D ] \tof\n",
      "digitizing     \t[ P A D ] \tdigitizing\n",
      "life           \t[ P A D ] \tlife\n",
      "has            \t[ P A D ] \thas\n",
      "been           \t[ P A D ] \tbeen\n",
      "increasing     \t[ P A D ] \tincreasing\n",
      "at             \t[ P A D ] \tat\n",
      "an             \t[ P A D ] \tan\n",
      "exponential    \t[ P A D ] \texponential\n",
      "pace           \t.         \tpace.\n",
      "our            \t[ P A D ] \tour\n",
      "ability        \t[ P A D ] \tability\n",
      "to             \t[ P A D ] \tto\n",
      "write          \t[ P A D ] \twrite\n",
      "the            \t[ P A D ] \tthe\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t[ P A D ] \tcode\n",
      "has            \t[ P A D ] \thas\n",
      "been           \t[ P A D ] \tbeen\n",
      "moving         \t[ P A D ] \tmoving\n",
      "pretty         \t[ P A D ] \tpretty\n",
      "slowly         \t,         \tslowly,\n",
      "but            \t[ P A D ] \tbut\n",
      "has            \t[ P A D ] \thas\n",
      "been           \t[ P A D ] \tbeen\n",
      "increasing     \t.         \tincreasing.\n",
      "and            \t[ P A D ] \tand\n",
      "our            \t[ P A D ] \tour\n",
      "latest         \t[ P A D ] \tlatest\n",
      "point          \t[ P A D ] \tpoint\n",
      "would          \t[ P A D ] \twould\n",
      "put            \t[ P A D ] \tput\n",
      "it             \t[ P A D ] \tit\n",
      "on             \t[ P A D ] \ton\n",
      "now            \t[ P A D ] \tnow\n",
      "an             \t[ P A D ] \tan\n",
      "exponential    \t[ P A D ] \texponential\n",
      "curve          \t.         \tcurve.\n",
      "we             \t[ P A D ] \twe\n",
      "started        \t[ P A D ] \tstarted\n",
      "this           \t[ P A D ] \tthis\n",
      "over           \t[ P A D ] \tover\n",
      "15             \t[ P A D ] \t15\n",
      "years          \t[ P A D ] \tyears\n",
      "ago            \t.         \tago.\n",
      "it             \t[ P A D ] \tit\n",
      "took           \t[ P A D ] \ttook\n",
      "several        \t[ P A D ] \tseveral\n",
      "stages         \t,         \tstages,\n",
      "in             \t[ P A D ] \tin\n",
      "fact           \t,         \tfact,\n",
      "starting       \t[ P A D ] \tstarting\n",
      "with           \t[ P A D ] \twith\n",
      "a              \t[ P A D ] \ta\n",
      "bioethical     \t[ P A D ] \tbioethical\n",
      "review         \t[ P A D ] \treview\n",
      "before         \t[ P A D ] \tbefore\n",
      "we             \t[ P A D ] \twe\n",
      "did            \t[ P A D ] \tdid\n",
      "the            \t[ P A D ] \tthe\n",
      "first          \t[ P A D ] \tfirst\n",
      "experiments    \t.         \texperiments.\n",
      "but            \t[ P A D ] \tbut\n",
      "it             \t[ P A D ] \tit\n",
      "turns          \t[ P A D ] \tturns\n",
      "out            \t[ P A D ] \tout\n",
      "synthesizing   \t[ P A D ] \tsynthesizing\n",
      "dna            \t[ P A D ] \tdna\n",
      "is             \t[ P A D ] \tis\n",
      "very           \t[ P A D ] \tvery\n",
      "difficult      \t.         \tdifficult.\n",
      "there's        \t[ P A D ] \tthere's\n",
      "tens           \t[ P A D ] \ttens\n",
      "of             \t[ P A D ] \tof\n",
      "thousands      \t[ P A D ] \tthousands\n",
      "of             \t[ P A D ] \tof\n",
      "machines       \t[ P A D ] \tmachines\n",
      "around         \t[ P A D ] \taround\n",
      "the            \t[ P A D ] \tthe\n",
      "world          \t[ P A D ] \tworld\n",
      "that           \t[ P A D ] \tthat\n",
      "make           \t[ P A D ] \tmake\n",
      "small          \t[ P A D ] \tsmall\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "of             \t[ P A D ] \tof\n",
      "dna            \t,         \tdna,\n",
      "30             \t[ P A D ] \t30\n",
      "to             \t[ P A D ] \tto\n",
      "50             \t[ P A D ] \t50\n",
      "letters        \t[ P A D ] \tletters\n",
      "in             \t[ P A D ] \tin\n",
      "length         \t,         \tlength,\n",
      "and            \t[ P A D ] \tand\n",
      "it's           \t[ P A D ] \tit's\n",
      "a              \t[ P A D ] \ta\n",
      "degenerate     \t[ P A D ] \tdegenerate\n",
      "process        \t,         \tprocess,\n",
      "so             \t[ P A D ] \tso\n",
      "the            \t[ P A D ] \tthe\n",
      "longer         \t[ P A D ] \tlonger\n",
      "you            \t[ P A D ] \tyou\n",
      "make           \t[ P A D ] \tmake\n",
      "the            \t[ P A D ] \tthe\n",
      "piece          \t,         \tpiece,\n",
      "the            \t[ P A D ] \tthe\n",
      "more           \t[ P A D ] \tmore\n",
      "errors         \t[ P A D ] \terrors\n",
      "there          \t[ P A D ] \tthere\n",
      "are            \t.         \tare.\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "had            \t[ P A D ] \thad\n",
      "to             \t[ P A D ] \tto\n",
      "create         \t[ P A D ] \tcreate\n",
      "a              \t[ P A D ] \ta\n",
      "new            \t[ P A D ] \tnew\n",
      "method         \t[ P A D ] \tmethod\n",
      "for            \t[ P A D ] \tfor\n",
      "putting        \t[ P A D ] \tputting\n",
      "these          \t[ P A D ] \tthese\n",
      "little         \t[ P A D ] \tlittle\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "together       \t[ P A D ] \ttogether\n",
      "and            \t[ P A D ] \tand\n",
      "correct        \t[ P A D ] \tcorrect\n",
      "all            \t[ P A D ] \tall\n",
      "the            \t[ P A D ] \tthe\n",
      "errors         \t.         \terrors.\n",
      "and            \t[ P A D ] \tand\n",
      "this           \t[ P A D ] \tthis\n",
      "was            \t[ P A D ] \twas\n",
      "our            \t[ P A D ] \tour\n",
      "first          \t[ P A D ] \tfirst\n",
      "attempt        \t,         \tattempt,\n",
      "starting       \t[ P A D ] \tstarting\n",
      "with           \t[ P A D ] \twith\n",
      "the            \t[ P A D ] \tthe\n",
      "digital        \t[ P A D ] \tdigital\n",
      "information    \t[ P A D ] \tinformation\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "genome         \t[ P A D ] \tgenome\n",
      "of             \t[ P A D ] \tof\n",
      "phi            \t[ P A D ] \tphi\n",
      "x              \t[ P A D ] \tx\n",
      "174            \t.         \t174.\n",
      "it's           \t[ P A D ] \tit's\n",
      "a              \t[ P A D ] \ta\n",
      "small          \t[ P A D ] \tsmall\n",
      "virus          \t[ P A D ] \tvirus\n",
      "that           \t[ P A D ] \tthat\n",
      "kills          \t[ P A D ] \tkills\n",
      "bacteria       \t.         \tbacteria.\n",
      "we             \t[ P A D ] \twe\n",
      "designed       \t[ P A D ] \tdesigned\n",
      "the            \t[ P A D ] \tthe\n",
      "pieces         \t,         \tpieces,\n",
      "went           \t[ P A D ] \twent\n",
      "through        \t[ P A D ] \tthrough\n",
      "our            \t[ P A D ] \tour\n",
      "error          \t[ P A D ] \terror\n",
      "correction     \t,         \tcorrection,\n",
      "and            \t[ P A D ] \tand\n",
      "had            \t[ P A D ] \thad\n",
      "a              \t[ P A D ] \ta\n",
      "dna            \t[ P A D ] \tdna\n",
      "molecule       \t[ P A D ] \tmolecule\n",
      "of             \t[ P A D ] \tof\n",
      "about          \t[ P A D ] \tabout\n",
      "5, 000         \t[ P A D ] \t5,000\n",
      "letters        \t.         \tletters.\n",
      "the            \t[ P A D ] \tthe\n",
      "exciting       \t[ P A D ] \texciting\n",
      "phase          \t[ P A D ] \tphase\n",
      "came           \t[ P A D ] \tcame\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "took           \t[ P A D ] \ttook\n",
      "this           \t[ P A D ] \tthis\n",
      "piece          \t[ P A D ] \tpiece\n",
      "of             \t[ P A D ] \tof\n",
      "inert          \t[ P A D ] \tinert\n",
      "chemical       \t[ P A D ] \tchemical\n",
      "and            \t[ P A D ] \tand\n",
      "put            \t[ P A D ] \tput\n",
      "it             \t[ P A D ] \tit\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "bacteria       \t,         \tbacteria,\n",
      "and            \t[ P A D ] \tand\n",
      "the            \t[ P A D ] \tthe\n",
      "bacteria       \t[ P A D ] \tbacteria\n",
      "started        \t[ P A D ] \tstarted\n",
      "to             \t[ P A D ] \tto\n",
      "read           \t[ P A D ] \tread\n",
      "this           \t[ P A D ] \tthis\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t,         \tcode,\n",
      "made           \t[ P A D ] \tmade\n",
      "the            \t[ P A D ] \tthe\n",
      "viral          \t[ P A D ] \tviral\n",
      "particles      \t.         \tparticles.\n",
      "the            \t[ P A D ] \tthe\n",
      "viral          \t[ P A D ] \tviral\n",
      "particles      \t[ P A D ] \tparticles\n",
      "then           \t[ P A D ] \tthen\n",
      "were           \t[ P A D ] \twere\n",
      "released       \t[ P A D ] \treleased\n",
      "from           \t[ P A D ] \tfrom\n",
      "the            \t[ P A D ] \tthe\n",
      "cells          \t,         \tcells,\n",
      "then           \t[ P A D ] \tthen\n",
      "came           \t[ P A D ] \tcame\n",
      "back           \t[ P A D ] \tback\n",
      "and            \t[ P A D ] \tand\n",
      "killed         \t[ P A D ] \tkilled\n",
      "the            \t[ P A D ] \tthe\n",
      "e              \t.         \te.\n",
      "coli           \t.         \tcoli.\n",
      "i              \t[ P A D ] \ti\n",
      "was            \t[ P A D ] \twas\n",
      "talking        \t[ P A D ] \ttalking\n",
      "to             \t[ P A D ] \tto\n",
      "the            \t[ P A D ] \tthe\n",
      "oil            \t[ P A D ] \toil\n",
      "industry       \t[ P A D ] \tindustry\n",
      "recently       \t,         \trecently,\n",
      "and            \t[ P A D ] \tand\n",
      "i              \t[ P A D ] \ti\n",
      "said           \t[ P A D ] \tsaid\n",
      "they           \t[ P A D ] \tthey\n",
      "clearly        \t[ P A D ] \tclearly\n",
      "understood     \t[ P A D ] \tunderstood\n",
      "that           \t[ P A D ] \tthat\n",
      "model          \t.         \tmodel.\n",
      "they           \t[ P A D ] \tthey\n",
      "laughed        \t[ P A D ] \tlaughed\n",
      "more           \t[ P A D ] \tmore\n",
      "than           \t[ P A D ] \tthan\n",
      "you            \t[ P A D ] \tyou\n",
      "guys           \t[ P A D ] \tguys\n",
      "are            \t.         \tare.\n",
      "and            \t[ P A D ] \tand\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "think          \t[ P A D ] \tthink\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "a              \t[ P A D ] \ta\n",
      "situation      \t[ P A D ] \tsituation\n",
      "where          \t[ P A D ] \twhere\n",
      "the            \t[ P A D ] \tthe\n",
      "software       \t[ P A D ] \tsoftware\n",
      "can            \t[ P A D ] \tcan\n",
      "actually       \t[ P A D ] \tactually\n",
      "build          \t[ P A D ] \tbuild\n",
      "its            \t[ P A D ] \tits\n",
      "own            \t[ P A D ] \town\n",
      "hardware       \t[ P A D ] \thardware\n",
      "in             \t[ P A D ] \tin\n",
      "a              \t[ P A D ] \ta\n",
      "biological     \t[ P A D ] \tbiological\n",
      "system         \t.         \tsystem.\n",
      "but            \t[ P A D ] \tbut\n",
      "we             \t[ P A D ] \twe\n",
      "wanted         \t[ P A D ] \twanted\n",
      "to             \t[ P A D ] \tto\n",
      "go             \t[ P A D ] \tgo\n",
      "much           \t[ P A D ] \tmuch\n",
      "larger         \t.         \tlarger.\n",
      "we             \t[ P A D ] \twe\n",
      "wanted         \t[ P A D ] \twanted\n",
      "to             \t[ P A D ] \tto\n",
      "build          \t[ P A D ] \tbuild\n",
      "the            \t[ P A D ] \tthe\n",
      "entire         \t[ P A D ] \tentire\n",
      "bacterial      \t[ P A D ] \tbacterial\n",
      "chromosome     \t.         \tchromosome.\n",
      "it's           \t[ P A D ] \tit's\n",
      "over           \t[ P A D ] \tover\n",
      "580, 000       \t[ P A D ] \t580,000\n",
      "letters        \t[ P A D ] \tletters\n",
      "of             \t[ P A D ] \tof\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t.         \tcode.\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "thought        \t[ P A D ] \tthought\n",
      "we'd           \t[ P A D ] \twe'd\n",
      "build          \t[ P A D ] \tbuild\n",
      "them           \t[ P A D ] \tthem\n",
      "in             \t[ P A D ] \tin\n",
      "cassettes      \t[ P A D ] \tcassettes\n",
      "the            \t[ P A D ] \tthe\n",
      "size           \t[ P A D ] \tsize\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "viruses        \t,         \tviruses,\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "could          \t[ P A D ] \tcould\n",
      "actually       \t[ P A D ] \tactually\n",
      "vary           \t[ P A D ] \tvary\n",
      "the            \t[ P A D ] \tthe\n",
      "cassettes      \t[ P A D ] \tcassettes\n",
      "to             \t[ P A D ] \tto\n",
      "understand     \t[ P A D ] \tunderstand\n",
      "what           \t[ P A D ] \twhat\n",
      "the            \t[ P A D ] \tthe\n",
      "actual         \t[ P A D ] \tactual\n",
      "components     \t[ P A D ] \tcomponents\n",
      "of             \t[ P A D ] \tof\n",
      "a              \t[ P A D ] \ta\n",
      "living         \t[ P A D ] \tliving\n",
      "cell           \t[ P A D ] \tcell\n",
      "are            \t.         \tare.\n",
      "design         \t[ P A D ] \tdesign\n",
      "is             \t[ P A D ] \tis\n",
      "critical       \t,         \tcritical,\n",
      "and            \t[ P A D ] \tand\n",
      "if             \t[ P A D ] \tif\n",
      "you're         \t[ P A D ] \tyou're\n",
      "starting       \t[ P A D ] \tstarting\n",
      "with           \t[ P A D ] \twith\n",
      "digital        \t[ P A D ] \tdigital\n",
      "information    \t[ P A D ] \tinformation\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "computer       \t,         \tcomputer,\n",
      "that           \t[ P A D ] \tthat\n",
      "digital        \t[ P A D ] \tdigital\n",
      "information    \t[ P A D ] \tinformation\n",
      "has            \t[ P A D ] \thas\n",
      "to             \t[ P A D ] \tto\n",
      "be             \t[ P A D ] \tbe\n",
      "really         \t[ P A D ] \treally\n",
      "accurate       \t.         \taccurate.\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "first          \t[ P A D ] \tfirst\n",
      "sequenced      \t[ P A D ] \tsequenced\n",
      "this           \t[ P A D ] \tthis\n",
      "genome         \t[ P A D ] \tgenome\n",
      "in             \t[ P A D ] \tin\n",
      "1995           \t,         \t1995,\n",
      "the            \t[ P A D ] \tthe\n",
      "standard       \t[ P A D ] \tstandard\n",
      "of             \t[ P A D ] \tof\n",
      "accuracy       \t[ P A D ] \taccuracy\n",
      "was            \t[ P A D ] \twas\n",
      "one            \t[ P A D ] \tone\n",
      "error          \t[ P A D ] \terror\n",
      "per            \t[ P A D ] \tper\n",
      "10, 000        \t[ P A D ] \t10,000\n",
      "base           \t[ P A D ] \tbase\n",
      "pairs          \t.         \tpairs.\n",
      "we             \t[ P A D ] \twe\n",
      "actually       \t[ P A D ] \tactually\n",
      "found          \t,         \tfound,\n",
      "on             \t[ P A D ] \ton\n",
      "resequencing   \t[ P A D ] \tresequencing\n",
      "it             \t,         \tit,\n",
      "30             \t[ P A D ] \t30\n",
      "errors         \t.         \terrors.\n",
      "had            \t[ P A D ] \thad\n",
      "we             \t[ P A D ] \twe\n",
      "used           \t[ P A D ] \tused\n",
      "that           \t[ P A D ] \tthat\n",
      "original       \t[ P A D ] \toriginal\n",
      "sequence       \t,         \tsequence,\n",
      "it             \t[ P A D ] \tit\n",
      "never          \t[ P A D ] \tnever\n",
      "would          \t[ P A D ] \twould\n",
      "have           \t[ P A D ] \thave\n",
      "been           \t[ P A D ] \tbeen\n",
      "able           \t[ P A D ] \table\n",
      "to             \t[ P A D ] \tto\n",
      "be             \t[ P A D ] \tbe\n",
      "booted         \t[ P A D ] \tbooted\n",
      "up             \t.         \tup.\n",
      "part           \t[ P A D ] \tpart\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "design         \t[ P A D ] \tdesign\n",
      "is             \t[ P A D ] \tis\n",
      "designing      \t[ P A D ] \tdesigning\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "that           \t[ P A D ] \tthat\n",
      "are            \t[ P A D ] \tare\n",
      "50             \t[ P A D ] \t50\n",
      "letters        \t[ P A D ] \tletters\n",
      "long           \t[ P A D ] \tlong\n",
      "that           \t[ P A D ] \tthat\n",
      "have           \t[ P A D ] \thave\n",
      "to             \t[ P A D ] \tto\n",
      "overlap        \t[ P A D ] \toverlap\n",
      "with           \t[ P A D ] \twith\n",
      "all            \t[ P A D ] \tall\n",
      "the            \t[ P A D ] \tthe\n",
      "other          \t[ P A D ] \tother\n",
      "50 - letter    \t[ P A D ] \t50-letter\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "to             \t[ P A D ] \tto\n",
      "build          \t[ P A D ] \tbuild\n",
      "smaller        \t[ P A D ] \tsmaller\n",
      "sub            \t[ P A D ] \tsub\n",
      "units          \t[ P A D ] \tunits\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "to             \t[ P A D ] \tto\n",
      "design         \t[ P A D ] \tdesign\n",
      "so             \t[ P A D ] \tso\n",
      "they           \t[ P A D ] \tthey\n",
      "can            \t[ P A D ] \tcan\n",
      "go             \t[ P A D ] \tgo\n",
      "together       \t.         \ttogether.\n",
      "we             \t[ P A D ] \twe\n",
      "design         \t[ P A D ] \tdesign\n",
      "unique         \t[ P A D ] \tunique\n",
      "elements       \t[ P A D ] \telements\n",
      "into           \t[ P A D ] \tinto\n",
      "this           \t.         \tthis.\n",
      "you            \t[ P A D ] \tyou\n",
      "may            \t[ P A D ] \tmay\n",
      "have           \t[ P A D ] \thave\n",
      "read           \t[ P A D ] \tread\n",
      "that           \t[ P A D ] \tthat\n",
      "we             \t[ P A D ] \twe\n",
      "put            \t[ P A D ] \tput\n",
      "watermarks     \t[ P A D ] \twatermarks\n",
      "in             \t.         \tin.\n",
      "think          \t[ P A D ] \tthink\n",
      "of             \t[ P A D ] \tof\n",
      "this           \t,         \tthis,\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "a              \t[ P A D ] \ta\n",
      "four           \t[ P A D ] \tfour\n",
      "letter         \t[ P A D ] \tletter\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t,         \tcode,\n",
      "a              \t,         \ta,\n",
      "c              \t,         \tc,\n",
      "g              \t[ P A D ] \tg\n",
      "and            \t[ P A D ] \tand\n",
      "t              \t.         \tt.\n",
      "triplets       \t[ P A D ] \ttriplets\n",
      "of             \t[ P A D ] \tof\n",
      "that           \t[ P A D ] \tthat\n",
      "letter         \t,         \tletter,\n",
      "those          \t[ P A D ] \tthose\n",
      "letters        \t[ P A D ] \tletters\n",
      "code           \t[ P A D ] \tcode\n",
      "for            \t[ P A D ] \tfor\n",
      "roughly        \t[ P A D ] \troughly\n",
      "20             \t[ P A D ] \t20\n",
      "amino          \t[ P A D ] \tamino\n",
      "acids          \t,         \tacids,\n",
      "that           \t[ P A D ] \tthat\n",
      "there's        \t[ P A D ] \tthere's\n",
      "a              \t[ P A D ] \ta\n",
      "single         \t[ P A D ] \tsingle\n",
      "letter         \t[ P A D ] \tletter\n",
      "designation    \t[ P A D ] \tdesignation\n",
      "for            \t[ P A D ] \tfor\n",
      "each           \t[ P A D ] \teach\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "amino          \t[ P A D ] \tamino\n",
      "acids          \t.         \tacids.\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "use            \t[ P A D ] \tuse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the            \t[ P A D ] \tthe\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t[ P A D ] \tcode\n",
      "to             \t[ P A D ] \tto\n",
      "write          \t[ P A D ] \twrite\n",
      "out            \t[ P A D ] \tout\n",
      "words          \t,         \twords,\n",
      "sentences      \t,         \tsentences,\n",
      "thoughts       \t.         \tthoughts.\n",
      "initially      \t,         \tinitially,\n",
      "all            \t[ P A D ] \tall\n",
      "we             \t[ P A D ] \twe\n",
      "did            \t[ P A D ] \tdid\n",
      "was            \t[ P A D ] \twas\n",
      "autograph      \t[ P A D ] \tautograph\n",
      "it             \t.         \tit.\n",
      "some           \t[ P A D ] \tsome\n",
      "people         \t[ P A D ] \tpeople\n",
      "were           \t[ P A D ] \twere\n",
      "disappointed   \t[ P A D ] \tdisappointed\n",
      "there          \t[ P A D ] \tthere\n",
      "was            \t[ P A D ] \twas\n",
      "not            \t[ P A D ] \tnot\n",
      "poetry         \t.         \tpoetry.\n",
      "we             \t[ P A D ] \twe\n",
      "designed       \t[ P A D ] \tdesigned\n",
      "these          \t[ P A D ] \tthese\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "just           \t[ P A D ] \tjust\n",
      "chew           \t[ P A D ] \tchew\n",
      "back           \t[ P A D ] \tback\n",
      "with           \t[ P A D ] \twith\n",
      "enzymes        \t.         \tenzymes.\n",
      "there's        \t[ P A D ] \tthere's\n",
      "enzymes        \t[ P A D ] \tenzymes\n",
      "that           \t[ P A D ] \tthat\n",
      "repair         \t[ P A D ] \trepair\n",
      "them           \t[ P A D ] \tthem\n",
      "and            \t[ P A D ] \tand\n",
      "put            \t[ P A D ] \tput\n",
      "them           \t[ P A D ] \tthem\n",
      "together       \t.         \ttogether.\n",
      "and            \t[ P A D ] \tand\n",
      "we             \t[ P A D ] \twe\n",
      "started        \t[ P A D ] \tstarted\n",
      "making         \t[ P A D ] \tmaking\n",
      "pieces         \t,         \tpieces,\n",
      "starting       \t[ P A D ] \tstarting\n",
      "with           \t[ P A D ] \twith\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "that           \t[ P A D ] \tthat\n",
      "were           \t[ P A D ] \twere\n",
      "five           \t[ P A D ] \tfive\n",
      "to             \t[ P A D ] \tto\n",
      "7, 000         \t[ P A D ] \t7,000\n",
      "letters        \t,         \tletters,\n",
      "fit            \t[ P A D ] \tfit\n",
      "those          \t[ P A D ] \tthose\n",
      "together       \t[ P A D ] \ttogether\n",
      "to             \t[ P A D ] \tto\n",
      "make           \t[ P A D ] \tmake\n",
      "24, 000 - letter\t[ P A D ] \t24,000-letter\n",
      "pieces         \t,         \tpieces,\n",
      "then           \t[ P A D ] \tthen\n",
      "put            \t[ P A D ] \tput\n",
      "sets           \t[ P A D ] \tsets\n",
      "of             \t[ P A D ] \tof\n",
      "those          \t,         \tthose,\n",
      "going          \t[ P A D ] \tgoing\n",
      "up             \t[ P A D ] \tup\n",
      "to             \t[ P A D ] \tto\n",
      "72, 000        \t.         \t72,000.\n",
      "at             \t[ P A D ] \tat\n",
      "each           \t[ P A D ] \teach\n",
      "stage          \t,         \tstage,\n",
      "we             \t[ P A D ] \twe\n",
      "grew           \t[ P A D ] \tgrew\n",
      "up             \t[ P A D ] \tup\n",
      "these          \t[ P A D ] \tthese\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "in             \t[ P A D ] \tin\n",
      "abundance      \t[ P A D ] \tabundance\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "could          \t[ P A D ] \tcould\n",
      "sequence       \t[ P A D ] \tsequence\n",
      "them           \t[ P A D ] \tthem\n",
      "because        \t[ P A D ] \tbecause\n",
      "we're          \t[ P A D ] \twe're\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "create         \t[ P A D ] \tcreate\n",
      "a              \t[ P A D ] \ta\n",
      "process        \t[ P A D ] \tprocess\n",
      "that's         \t[ P A D ] \tthat's\n",
      "extremely      \t[ P A D ] \textremely\n",
      "robust         \t,         \trobust,\n",
      "that           \t[ P A D ] \tthat\n",
      "you            \t[ P A D ] \tyou\n",
      "can            \t[ P A D ] \tcan\n",
      "see            \t[ P A D ] \tsee\n",
      "in             \t[ P A D ] \tin\n",
      "a              \t[ P A D ] \ta\n",
      "minute         \t.         \tminute.\n",
      "we're          \t[ P A D ] \twe're\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "get            \t[ P A D ] \tget\n",
      "to             \t[ P A D ] \tto\n",
      "the            \t[ P A D ] \tthe\n",
      "point          \t[ P A D ] \tpoint\n",
      "of             \t[ P A D ] \tof\n",
      "automation     \t.         \tautomation.\n",
      "so             \t,         \tso,\n",
      "this           \t[ P A D ] \tthis\n",
      "looks          \t[ P A D ] \tlooks\n",
      "like           \t[ P A D ] \tlike\n",
      "a              \t[ P A D ] \ta\n",
      "basketball     \t[ P A D ] \tbasketball\n",
      "playoff        \t.         \tplayoff.\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "get            \t[ P A D ] \tget\n",
      "into           \t[ P A D ] \tinto\n",
      "these          \t[ P A D ] \tthese\n",
      "really         \t[ P A D ] \treally\n",
      "large          \t[ P A D ] \tlarge\n",
      "pieces         \t,         \tpieces,\n",
      "over           \t[ P A D ] \tover\n",
      "100, 000       \t[ P A D ] \t100,000\n",
      "base           \t[ P A D ] \tbase\n",
      "pairs          \t,         \tpairs,\n",
      "they           \t[ P A D ] \tthey\n",
      "won't          \t[ P A D ] \twon't\n",
      "any            \t[ P A D ] \tany\n",
      "longer         \t[ P A D ] \tlonger\n",
      "grow           \t[ P A D ] \tgrow\n",
      "readily        \t[ P A D ] \treadily\n",
      "in             \t[ P A D ] \tin\n",
      "e              \t.         \te.\n",
      "coli           \t.         \tcoli.\n",
      "it             \t[ P A D ] \tit\n",
      "exhausts       \t[ P A D ] \texhausts\n",
      "all            \t[ P A D ] \tall\n",
      "the            \t[ P A D ] \tthe\n",
      "modern         \t[ P A D ] \tmodern\n",
      "tools          \t[ P A D ] \ttools\n",
      "of             \t[ P A D ] \tof\n",
      "molecular      \t[ P A D ] \tmolecular\n",
      "biology        \t.         \tbiology.\n",
      "and            \t[ P A D ] \tand\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "turned         \t[ P A D ] \tturned\n",
      "to             \t[ P A D ] \tto\n",
      "other          \t[ P A D ] \tother\n",
      "mechanisms     \t.         \tmechanisms.\n",
      "we             \t[ P A D ] \twe\n",
      "knew           \t[ P A D ] \tknew\n",
      "there's        \t[ P A D ] \tthere's\n",
      "a              \t[ P A D ] \ta\n",
      "mechanism      \t[ P A D ] \tmechanism\n",
      "called         \t[ P A D ] \tcalled\n",
      "homologous     \t[ P A D ] \thomologous\n",
      "recombination  \t,         \trecombination,\n",
      "that           \t[ P A D ] \tthat\n",
      "biology        \t[ P A D ] \tbiology\n",
      "uses           \t[ P A D ] \tuses\n",
      "to             \t[ P A D ] \tto\n",
      "repair         \t[ P A D ] \trepair\n",
      "dna            \t,         \tdna,\n",
      "that           \t[ P A D ] \tthat\n",
      "can            \t[ P A D ] \tcan\n",
      "put            \t[ P A D ] \tput\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "together       \t.         \ttogether.\n",
      "here's         \t[ P A D ] \there's\n",
      "an             \t[ P A D ] \tan\n",
      "example        \t[ P A D ] \texample\n",
      "of             \t[ P A D ] \tof\n",
      "it             \t.         \tit.\n",
      "there's        \t[ P A D ] \tthere's\n",
      "an             \t[ P A D ] \tan\n",
      "organism       \t[ P A D ] \torganism\n",
      "called         \t[ P A D ] \tcalled\n",
      "deinococcus    \t[ P A D ] \tdeinococcus\n",
      "radiodurans    \t[ P A D ] \tradiodurans\n",
      "that           \t[ P A D ] \tthat\n",
      "can            \t[ P A D ] \tcan\n",
      "take           \t[ P A D ] \ttake\n",
      "three          \t[ P A D ] \tthree\n",
      "millions       \t[ P A D ] \tmillions\n",
      "rads           \t[ P A D ] \trads\n",
      "of             \t[ P A D ] \tof\n",
      "radiation      \t.         \tradiation.\n",
      "you            \t[ P A D ] \tyou\n",
      "can            \t[ P A D ] \tcan\n",
      "see            \t[ P A D ] \tsee\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "top            \t[ P A D ] \ttop\n",
      "panel          \t,         \tpanel,\n",
      "its            \t[ P A D ] \tits\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "just           \t[ P A D ] \tjust\n",
      "gets           \t[ P A D ] \tgets\n",
      "blown          \t[ P A D ] \tblown\n",
      "apart          \t.         \tapart.\n",
      "12             \t[ P A D ] \t12\n",
      "to             \t[ P A D ] \tto\n",
      "24             \t[ P A D ] \t24\n",
      "hours          \t[ P A D ] \thours\n",
      "later          \t,         \tlater,\n",
      "it             \t[ P A D ] \tit\n",
      "put            \t[ P A D ] \tput\n",
      "it             \t[ P A D ] \tit\n",
      "back           \t[ P A D ] \tback\n",
      "together       \t[ P A D ] \ttogether\n",
      "exactly        \t[ P A D ] \texactly\n",
      "as             \t[ P A D ] \tas\n",
      "it             \t[ P A D ] \tit\n",
      "was            \t[ P A D ] \twas\n",
      "before         \t.         \tbefore.\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "thousands      \t[ P A D ] \tthousands\n",
      "of             \t[ P A D ] \tof\n",
      "organisms      \t[ P A D ] \torganisms\n",
      "that           \t[ P A D ] \tthat\n",
      "can            \t[ P A D ] \tcan\n",
      "do             \t[ P A D ] \tdo\n",
      "this           \t.         \tthis.\n",
      "these          \t[ P A D ] \tthese\n",
      "organisms      \t[ P A D ] \torganisms\n",
      "can            \t[ P A D ] \tcan\n",
      "be             \t[ P A D ] \tbe\n",
      "totally        \t[ P A D ] \ttotally\n",
      "desiccated     \t.         \tdesiccated.\n",
      "they           \t[ P A D ] \tthey\n",
      "can            \t[ P A D ] \tcan\n",
      "live           \t[ P A D ] \tlive\n",
      "in             \t[ P A D ] \tin\n",
      "a              \t[ P A D ] \ta\n",
      "vacuum         \t.         \tvacuum.\n",
      "i              \t[ P A D ] \ti\n",
      "am             \t[ P A D ] \tam\n",
      "absolutely     \t[ P A D ] \tabsolutely\n",
      "certain        \t[ P A D ] \tcertain\n",
      "that           \t[ P A D ] \tthat\n",
      "life           \t[ P A D ] \tlife\n",
      "can            \t[ P A D ] \tcan\n",
      "exist          \t[ P A D ] \texist\n",
      "in             \t[ P A D ] \tin\n",
      "outer          \t[ P A D ] \touter\n",
      "space          \t,         \tspace,\n",
      "move           \t[ P A D ] \tmove\n",
      "around         \t,         \taround,\n",
      "find           \t[ P A D ] \tfind\n",
      "a              \t[ P A D ] \ta\n",
      "new            \t[ P A D ] \tnew\n",
      "aqueous        \t[ P A D ] \taqueous\n",
      "environment    \t.         \tenvironment.\n",
      "in             \t[ P A D ] \tin\n",
      "fact           \t,         \tfact,\n",
      "nasa           \t[ P A D ] \tnasa\n",
      "has            \t[ P A D ] \thas\n",
      "shown          \t[ P A D ] \tshown\n",
      "a              \t[ P A D ] \ta\n",
      "lot            \t[ P A D ] \tlot\n",
      "of             \t[ P A D ] \tof\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "out            \t[ P A D ] \tout\n",
      "there          \t.         \tthere.\n",
      "here's         \t[ P A D ] \there's\n",
      "an             \t[ P A D ] \tan\n",
      "actual         \t[ P A D ] \tactual\n",
      "micrograph     \t[ P A D ] \tmicrograph\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "molecule       \t[ P A D ] \tmolecule\n",
      "we             \t[ P A D ] \twe\n",
      "built          \t[ P A D ] \tbuilt\n",
      "using          \t[ P A D ] \tusing\n",
      "these          \t[ P A D ] \tthese\n",
      "processes      \t,         \tprocesses,\n",
      "actually       \t[ P A D ] \tactually\n",
      "just           \t[ P A D ] \tjust\n",
      "using          \t[ P A D ] \tusing\n",
      "yeast          \t[ P A D ] \tyeast\n",
      "mechanisms     \t[ P A D ] \tmechanisms\n",
      "with           \t[ P A D ] \twith\n",
      "the            \t[ P A D ] \tthe\n",
      "right          \t[ P A D ] \tright\n",
      "design         \t[ P A D ] \tdesign\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "pieces         \t[ P A D ] \tpieces\n",
      "we             \t[ P A D ] \twe\n",
      "put            \t[ P A D ] \tput\n",
      "them           \t[ P A D ] \tthem\n",
      "in             \t.         \tin.\n",
      "yeast          \t[ P A D ] \tyeast\n",
      "puts           \t[ P A D ] \tputs\n",
      "them           \t[ P A D ] \tthem\n",
      "together       \t[ P A D ] \ttogether\n",
      "automatically  \t.         \tautomatically.\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "not            \t[ P A D ] \tnot\n",
      "an             \t[ P A D ] \tan\n",
      "electron       \t[ P A D ] \telectron\n",
      "micrograph     \t.         \tmicrograph.\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "just           \t[ P A D ] \tjust\n",
      "a              \t[ P A D ] \ta\n",
      "regular        \t[ P A D ] \tregular\n",
      "photomicrograph\t.         \tphotomicrograph.\n",
      "it's           \t[ P A D ] \tit's\n",
      "such           \t[ P A D ] \tsuch\n",
      "a              \t[ P A D ] \ta\n",
      "large          \t[ P A D ] \tlarge\n",
      "molecule       \t[ P A D ] \tmolecule\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "see            \t[ P A D ] \tsee\n",
      "it             \t[ P A D ] \tit\n",
      "with           \t[ P A D ] \twith\n",
      "a              \t[ P A D ] \ta\n",
      "light          \t[ P A D ] \tlight\n",
      "microscope     \t.         \tmicroscope.\n",
      "these          \t[ P A D ] \tthese\n",
      "are            \t[ P A D ] \tare\n",
      "pictures       \t[ P A D ] \tpictures\n",
      "over           \t[ P A D ] \tover\n",
      "about          \t[ P A D ] \tabout\n",
      "a              \t[ P A D ] \ta\n",
      "six            \t[ P A D ] \tsix\n",
      "second         \t[ P A D ] \tsecond\n",
      "period         \t.         \tperiod.\n",
      "so             \t[ P A D ] \tso\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "the            \t[ P A D ] \tthe\n",
      "publication    \t[ P A D ] \tpublication\n",
      "we             \t[ P A D ] \twe\n",
      "had            \t[ P A D ] \thad\n",
      "just           \t[ P A D ] \tjust\n",
      "a              \t[ P A D ] \ta\n",
      "short          \t[ P A D ] \tshort\n",
      "while          \t[ P A D ] \twhile\n",
      "ago            \t.         \tago.\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "over           \t[ P A D ] \tover\n",
      "580, 000       \t[ P A D ] \t580,000\n",
      "letters        \t[ P A D ] \tletters\n",
      "of             \t[ P A D ] \tof\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t.         \tcode.\n",
      "it's           \t[ P A D ] \tit's\n",
      "the            \t[ P A D ] \tthe\n",
      "largest        \t[ P A D ] \tlargest\n",
      "molecule       \t[ P A D ] \tmolecule\n",
      "ever           \t[ P A D ] \tever\n",
      "made           \t[ P A D ] \tmade\n",
      "by             \t[ P A D ] \tby\n",
      "humans         \t[ P A D ] \thumans\n",
      "of             \t[ P A D ] \tof\n",
      "a              \t[ P A D ] \ta\n",
      "defined        \t[ P A D ] \tdefined\n",
      "structure      \t.         \tstructure.\n",
      "it's           \t[ P A D ] \tit's\n",
      "over           \t[ P A D ] \tover\n",
      "300            \t[ P A D ] \t300\n",
      "million        \t[ P A D ] \tmillion\n",
      "molecular      \t[ P A D ] \tmolecular\n",
      "weight         \t.         \tweight.\n",
      "if             \t[ P A D ] \tif\n",
      "we             \t[ P A D ] \twe\n",
      "printed        \t[ P A D ] \tprinted\n",
      "out            \t[ P A D ] \tout\n",
      "at             \t[ P A D ] \tat\n",
      "a              \t[ P A D ] \ta\n",
      "10             \t[ P A D ] \t10\n",
      "font           \t[ P A D ] \tfont\n",
      "with           \t[ P A D ] \twith\n",
      "no             \t[ P A D ] \tno\n",
      "spacing        \t,         \tspacing,\n",
      "it             \t[ P A D ] \tit\n",
      "takes          \t[ P A D ] \ttakes\n",
      "142            \t[ P A D ] \t142\n",
      "pages          \t[ P A D ] \tpages\n",
      "just           \t[ P A D ] \tjust\n",
      "to             \t[ P A D ] \tto\n",
      "print          \t[ P A D ] \tprint\n",
      "this           \t[ P A D ] \tthis\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t.         \tcode.\n",
      "well           \t,         \twell,\n",
      "how            \t[ P A D ] \thow\n",
      "do             \t[ P A D ] \tdo\n",
      "we             \t[ P A D ] \twe\n",
      "boot           \t[ P A D ] \tboot\n",
      "up             \t[ P A D ] \tup\n",
      "a              \t[ P A D ] \ta\n",
      "chromosome     \t?         \tchromosome?\n",
      "how            \t[ P A D ] \thow\n",
      "do             \t[ P A D ] \tdo\n",
      "we             \t[ P A D ] \twe\n",
      "activate       \t[ P A D ] \tactivate\n",
      "this           \t?         \tthis?\n",
      "obviously      \t,         \tobviously,\n",
      "with           \t[ P A D ] \twith\n",
      "a              \t[ P A D ] \ta\n",
      "virus          \t[ P A D ] \tvirus\n",
      "it's           \t[ P A D ] \tit's\n",
      "pretty         \t[ P A D ] \tpretty\n",
      "simple         \t.         \tsimple.\n",
      "it's           \t[ P A D ] \tit's\n",
      "much           \t[ P A D ] \tmuch\n",
      "more           \t[ P A D ] \tmore\n",
      "complicated    \t[ P A D ] \tcomplicated\n",
      "dealing        \t[ P A D ] \tdealing\n",
      "with           \t[ P A D ] \twith\n",
      "bacteria       \t.         \tbacteria.\n",
      "it's           \t[ P A D ] \tit's\n",
      "also           \t[ P A D ] \talso\n",
      "simpler        \t[ P A D ] \tsimpler\n",
      "when           \t[ P A D ] \twhen\n",
      "you            \t[ P A D ] \tyou\n",
      "go             \t[ P A D ] \tgo\n",
      "into           \t[ P A D ] \tinto\n",
      "eukaryotes     \t[ P A D ] \teukaryotes\n",
      "like           \t[ P A D ] \tlike\n",
      "ourselves      \t,         \tourselves,\n",
      "you            \t[ P A D ] \tyou\n",
      "can            \t[ P A D ] \tcan\n",
      "just           \t[ P A D ] \tjust\n",
      "pop            \t[ P A D ] \tpop\n",
      "out            \t[ P A D ] \tout\n",
      "the            \t[ P A D ] \tthe\n",
      "nucleus        \t[ P A D ] \tnucleus\n",
      "and            \t[ P A D ] \tand\n",
      "pop            \t[ P A D ] \tpop\n",
      "in             \t[ P A D ] \tin\n",
      "another        \t[ P A D ] \tanother\n",
      "one            \t,         \tone,\n",
      "and            \t[ P A D ] \tand\n",
      "that's         \t[ P A D ] \tthat's\n",
      "what           \t[ P A D ] \twhat\n",
      "you've         \t[ P A D ] \tyou've\n",
      "all            \t[ P A D ] \tall\n",
      "heard          \t[ P A D ] \theard\n",
      "about          \t[ P A D ] \tabout\n",
      "with           \t[ P A D ] \twith\n",
      "cloning        \t.         \tcloning.\n",
      "with           \t[ P A D ] \twith\n",
      "bacteria       \t[ P A D ] \tbacteria\n",
      "archaea        \t,         \tarchaea,\n",
      "the            \t[ P A D ] \tthe\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "is             \t[ P A D ] \tis\n",
      "integrated     \t[ P A D ] \tintegrated\n",
      "into           \t[ P A D ] \tinto\n",
      "the            \t[ P A D ] \tthe\n",
      "cell           \t,         \tcell,\n",
      "but            \t[ P A D ] \tbut\n",
      "we             \t[ P A D ] \twe\n",
      "recently       \t[ P A D ] \trecently\n",
      "showed         \t[ P A D ] \tshowed\n",
      "that           \t[ P A D ] \tthat\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "do             \t[ P A D ] \tdo\n",
      "a              \t[ P A D ] \ta\n",
      "complete       \t[ P A D ] \tcomplete\n",
      "transplant     \t[ P A D ] \ttransplant\n",
      "of             \t[ P A D ] \tof\n",
      "a              \t[ P A D ] \ta\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "from           \t[ P A D ] \tfrom\n",
      "one            \t[ P A D ] \tone\n",
      "cell           \t[ P A D ] \tcell\n",
      "to             \t[ P A D ] \tto\n",
      "another        \t[ P A D ] \tanother\n",
      "and            \t[ P A D ] \tand\n",
      "activate       \t[ P A D ] \tactivate\n",
      "it             \t.         \tit.\n",
      "we             \t[ P A D ] \twe\n",
      "purified       \t[ P A D ] \tpurified\n",
      "a              \t[ P A D ] \ta\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "from           \t[ P A D ] \tfrom\n",
      "one            \t[ P A D ] \tone\n",
      "microbial      \t[ P A D ] \tmicrobial\n",
      "species        \t.         \tspecies.\n",
      "roughly        \t,         \troughly,\n",
      "these          \t[ P A D ] \tthese\n",
      "two            \t[ P A D ] \ttwo\n",
      "are            \t[ P A D ] \tare\n",
      "as             \t[ P A D ] \tas\n",
      "distant        \t[ P A D ] \tdistant\n",
      "as             \t[ P A D ] \tas\n",
      "human          \t[ P A D ] \thuman\n",
      "and            \t[ P A D ] \tand\n",
      "mice           \t.         \tmice.\n",
      "we             \t[ P A D ] \twe\n",
      "added          \t[ P A D ] \tadded\n",
      "a              \t[ P A D ] \ta\n",
      "few            \t[ P A D ] \tfew\n",
      "extra          \t[ P A D ] \textra\n",
      "genes          \t[ P A D ] \tgenes\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "could          \t[ P A D ] \tcould\n",
      "select         \t[ P A D ] \tselect\n",
      "for            \t[ P A D ] \tfor\n",
      "this           \t[ P A D ] \tthis\n",
      "chromosome     \t.         \tchromosome.\n",
      "we             \t[ P A D ] \twe\n",
      "digested       \t[ P A D ] \tdigested\n",
      "it             \t[ P A D ] \tit\n",
      "with           \t[ P A D ] \twith\n",
      "enzymes        \t[ P A D ] \tenzymes\n",
      "to             \t[ P A D ] \tto\n",
      "kill           \t[ P A D ] \tkill\n",
      "all            \t[ P A D ] \tall\n",
      "the            \t[ P A D ] \tthe\n",
      "proteins       \t.         \tproteins.\n",
      "and            \t[ P A D ] \tand\n",
      "it             \t[ P A D ] \tit\n",
      "was            \t[ P A D ] \twas\n",
      "pretty         \t[ P A D ] \tpretty\n",
      "stunning       \t[ P A D ] \tstunning\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "put            \t[ P A D ] \tput\n",
      "this           \t[ P A D ] \tthis\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "cell           \t,         \tcell,\n",
      "and            \t[ P A D ] \tand\n",
      "you'll         \t[ P A D ] \tyou'll\n",
      "appreciate     \t[ P A D ] \tappreciate\n",
      "our            \t[ P A D ] \tour\n",
      "very           \t[ P A D ] \tvery\n",
      "sophisticated  \t[ P A D ] \tsophisticated\n",
      "graphics       \t[ P A D ] \tgraphics\n",
      "here           \t,         \there,\n",
      "the            \t[ P A D ] \tthe\n",
      "new            \t[ P A D ] \tnew\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "went           \t[ P A D ] \twent\n",
      "into           \t[ P A D ] \tinto\n",
      "the            \t[ P A D ] \tthe\n",
      "cell           \t.         \tcell.\n",
      "in             \t[ P A D ] \tin\n",
      "fact           \t,         \tfact,\n",
      "we             \t[ P A D ] \twe\n",
      "thought        \t[ P A D ] \tthought\n",
      "this           \t[ P A D ] \tthis\n",
      "might          \t[ P A D ] \tmight\n",
      "be             \t[ P A D ] \tbe\n",
      "as             \t[ P A D ] \tas\n",
      "far            \t[ P A D ] \tfar\n",
      "as             \t[ P A D ] \tas\n",
      "it             \t[ P A D ] \tit\n",
      "went           \t,         \twent,\n",
      "but            \t[ P A D ] \tbut\n",
      "we             \t[ P A D ] \twe\n",
      "tried          \t[ P A D ] \ttried\n",
      "to             \t[ P A D ] \tto\n",
      "design         \t[ P A D ] \tdesign\n",
      "the            \t[ P A D ] \tthe\n",
      "process        \t[ P A D ] \tprocess\n",
      "a              \t[ P A D ] \ta\n",
      "little         \t[ P A D ] \tlittle\n",
      "bit            \t[ P A D ] \tbit\n",
      "further        \t.         \tfurther.\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "a              \t[ P A D ] \ta\n",
      "major          \t[ P A D ] \tmajor\n",
      "mechanism      \t[ P A D ] \tmechanism\n",
      "of             \t[ P A D ] \tof\n",
      "evolution      \t[ P A D ] \tevolution\n",
      "right          \t[ P A D ] \tright\n",
      "here           \t.         \there.\n",
      "we             \t[ P A D ] \twe\n",
      "find           \t[ P A D ] \tfind\n",
      "all            \t[ P A D ] \tall\n",
      "kinds          \t[ P A D ] \tkinds\n",
      "of             \t[ P A D ] \tof\n",
      "species        \t[ P A D ] \tspecies\n",
      "that           \t[ P A D ] \tthat\n",
      "have           \t[ P A D ] \thave\n",
      "taken          \t[ P A D ] \ttaken\n",
      "up             \t[ P A D ] \tup\n",
      "a              \t[ P A D ] \ta\n",
      "second         \t[ P A D ] \tsecond\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "or             \t[ P A D ] \tor\n",
      "a              \t[ P A D ] \ta\n",
      "third          \t[ P A D ] \tthird\n",
      "one            \t[ P A D ] \tone\n",
      "from           \t[ P A D ] \tfrom\n",
      "somewhere      \t,         \tsomewhere,\n",
      "adding         \t[ P A D ] \tadding\n",
      "thousands      \t[ P A D ] \tthousands\n",
      "of             \t[ P A D ] \tof\n",
      "new            \t[ P A D ] \tnew\n",
      "traits         \t[ P A D ] \ttraits\n",
      "in             \t[ P A D ] \tin\n",
      "a              \t[ P A D ] \ta\n",
      "second         \t[ P A D ] \tsecond\n",
      "to             \t[ P A D ] \tto\n",
      "that           \t[ P A D ] \tthat\n",
      "species        \t.         \tspecies.\n",
      "so             \t[ P A D ] \tso\n",
      "people         \t[ P A D ] \tpeople\n",
      "who            \t[ P A D ] \twho\n",
      "think          \t[ P A D ] \tthink\n",
      "of             \t[ P A D ] \tof\n",
      "evolution      \t[ P A D ] \tevolution\n",
      "as             \t[ P A D ] \tas\n",
      "just           \t[ P A D ] \tjust\n",
      "one            \t[ P A D ] \tone\n",
      "gene           \t[ P A D ] \tgene\n",
      "changing       \t[ P A D ] \tchanging\n",
      "at             \t[ P A D ] \tat\n",
      "a              \t[ P A D ] \ta\n",
      "time           \t[ P A D ] \ttime\n",
      "have           \t[ P A D ] \thave\n",
      "missed         \t[ P A D ] \tmissed\n",
      "much           \t[ P A D ] \tmuch\n",
      "of             \t[ P A D ] \tof\n",
      "biology        \t.         \tbiology.\n",
      "there's        \t[ P A D ] \tthere's\n",
      "enzymes        \t[ P A D ] \tenzymes\n",
      "called         \t[ P A D ] \tcalled\n",
      "restriction    \t[ P A D ] \trestriction\n",
      "enzymes        \t[ P A D ] \tenzymes\n",
      "that           \t[ P A D ] \tthat\n",
      "actually       \t[ P A D ] \tactually\n",
      "digest         \t[ P A D ] \tdigest\n",
      "dna            \t.         \tdna.\n",
      "the            \t[ P A D ] \tthe\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "that           \t[ P A D ] \tthat\n",
      "was            \t[ P A D ] \twas\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "cell           \t[ P A D ] \tcell\n",
      "doesn't        \t[ P A D ] \tdoesn't\n",
      "have           \t[ P A D ] \thave\n",
      "one            \t.         \tone.\n",
      "the            \t[ P A D ] \tthe\n",
      "cell           \t,         \tcell,\n",
      "the            \t[ P A D ] \tthe\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "we             \t[ P A D ] \twe\n",
      "put            \t[ P A D ] \tput\n",
      "in             \t,         \tin,\n",
      "does           \t.         \tdoes.\n",
      "it             \t[ P A D ] \tit\n",
      "got            \t[ P A D ] \tgot\n",
      "expressed      \t,         \texpressed,\n",
      "and            \t[ P A D ] \tand\n",
      "it             \t[ P A D ] \tit\n",
      "recognized     \t[ P A D ] \trecognized\n",
      "the            \t[ P A D ] \tthe\n",
      "other          \t[ P A D ] \tother\n",
      "chromosome     \t[ P A D ] \tchromosome\n",
      "as             \t[ P A D ] \tas\n",
      "foreign        \t[ P A D ] \tforeign\n",
      "material       \t,         \tmaterial,\n",
      "chewed         \t[ P A D ] \tchewed\n",
      "it             \t[ P A D ] \tit\n",
      "up             \t,         \tup,\n",
      "and            \t[ P A D ] \tand\n",
      "so             \t[ P A D ] \tso\n",
      "we             \t[ P A D ] \twe\n",
      "ended          \t[ P A D ] \tended\n",
      "up             \t[ P A D ] \tup\n",
      "just           \t[ P A D ] \tjust\n",
      "with           \t[ P A D ] \twith\n",
      "the            \t[ P A D ] \tthe\n",
      "cell           \t[ P A D ] \tcell\n",
      "with           \t[ P A D ] \twith\n",
      "the            \t[ P A D ] \tthe\n",
      "new            \t[ P A D ] \tnew\n",
      "chromosome     \t.         \tchromosome.\n",
      "it             \t[ P A D ] \tit\n",
      "turned         \t[ P A D ] \tturned\n",
      "blue           \t[ P A D ] \tblue\n",
      "because        \t[ P A D ] \tbecause\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "genes          \t[ P A D ] \tgenes\n",
      "we             \t[ P A D ] \twe\n",
      "put            \t[ P A D ] \tput\n",
      "in             \t[ P A D ] \tin\n",
      "it             \t.         \tit.\n",
      "and            \t[ P A D ] \tand\n",
      "with           \t[ P A D ] \twith\n",
      "a              \t[ P A D ] \ta\n",
      "very           \t[ P A D ] \tvery\n",
      "short          \t[ P A D ] \tshort\n",
      "period         \t[ P A D ] \tperiod\n",
      "of             \t[ P A D ] \tof\n",
      "time           \t,         \ttime,\n",
      "all            \t[ P A D ] \tall\n",
      "the            \t[ P A D ] \tthe\n",
      "characteristics\t[ P A D ] \tcharacteristics\n",
      "of             \t[ P A D ] \tof\n",
      "one            \t[ P A D ] \tone\n",
      "species        \t[ P A D ] \tspecies\n",
      "were           \t[ P A D ] \twere\n",
      "lost           \t,         \tlost,\n",
      "and            \t[ P A D ] \tand\n",
      "it             \t[ P A D ] \tit\n",
      "converted      \t[ P A D ] \tconverted\n",
      "totally        \t[ P A D ] \ttotally\n",
      "into           \t[ P A D ] \tinto\n",
      "the            \t[ P A D ] \tthe\n",
      "new            \t[ P A D ] \tnew\n",
      "species        \t,         \tspecies,\n",
      "based          \t[ P A D ] \tbased\n",
      "on             \t[ P A D ] \ton\n",
      "the            \t[ P A D ] \tthe\n",
      "new            \t[ P A D ] \tnew\n",
      "software       \t[ P A D ] \tsoftware\n",
      "that           \t[ P A D ] \tthat\n",
      "we             \t[ P A D ] \twe\n",
      "put            \t[ P A D ] \tput\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "cell           \t.         \tcell.\n",
      "all            \t[ P A D ] \tall\n",
      "the            \t[ P A D ] \tthe\n",
      "proteins       \t[ P A D ] \tproteins\n",
      "changed        \t,         \tchanged,\n",
      "the            \t[ P A D ] \tthe\n",
      "membranes      \t[ P A D ] \tmembranes\n",
      "changed        \t,         \tchanged,\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "read           \t[ P A D ] \tread\n",
      "the            \t[ P A D ] \tthe\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t,         \tcode,\n",
      "it's           \t[ P A D ] \tit's\n",
      "exactly        \t[ P A D ] \texactly\n",
      "what           \t[ P A D ] \twhat\n",
      "we             \t[ P A D ] \twe\n",
      "had            \t[ P A D ] \thad\n",
      "transferred    \t[ P A D ] \ttransferred\n",
      "in             \t.         \tin.\n",
      "so             \t[ P A D ] \tso\n",
      "this           \t[ P A D ] \tthis\n",
      "may            \t[ P A D ] \tmay\n",
      "sound          \t[ P A D ] \tsound\n",
      "like           \t[ P A D ] \tlike\n",
      "genomic        \t[ P A D ] \tgenomic\n",
      "alchemy        \t,         \talchemy,\n",
      "but            \t[ P A D ] \tbut\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t,         \tcan,\n",
      "by             \t[ P A D ] \tby\n",
      "moving         \t[ P A D ] \tmoving\n",
      "the            \t[ P A D ] \tthe\n",
      "software       \t[ P A D ] \tsoftware\n",
      "dna            \t[ P A D ] \tdna\n",
      "around         \t,         \taround,\n",
      "change         \t[ P A D ] \tchange\n",
      "things         \t[ P A D ] \tthings\n",
      "quite          \t[ P A D ] \tquite\n",
      "dramatically   \t.         \tdramatically.\n",
      "now            \t,         \tnow,\n",
      "i've           \t[ P A D ] \ti've\n",
      "argued         \t,         \targued,\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "not            \t[ P A D ] \tnot\n",
      "genesis        \t,         \tgenesis,\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "building       \t[ P A D ] \tbuilding\n",
      "on             \t[ P A D ] \ton\n",
      "three          \t[ P A D ] \tthree\n",
      "and            \t[ P A D ] \tand\n",
      "a              \t[ P A D ] \ta\n",
      "half           \t[ P A D ] \thalf\n",
      "billion        \t[ P A D ] \tbillion\n",
      "years          \t[ P A D ] \tyears\n",
      "of             \t[ P A D ] \tof\n",
      "evolution      \t,         \tevolution,\n",
      "and            \t[ P A D ] \tand\n",
      "i've           \t[ P A D ] \ti've\n",
      "argued         \t[ P A D ] \targued\n",
      "that           \t[ P A D ] \tthat\n",
      "we're          \t[ P A D ] \twe're\n",
      "about          \t[ P A D ] \tabout\n",
      "to             \t[ P A D ] \tto\n",
      "perhaps        \t[ P A D ] \tperhaps\n",
      "create         \t[ P A D ] \tcreate\n",
      "a              \t[ P A D ] \ta\n",
      "new            \t[ P A D ] \tnew\n",
      "version        \t[ P A D ] \tversion\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "cambrian       \t[ P A D ] \tcambrian\n",
      "explosion      \t[ P A D ] \texplosion\n",
      "where          \t[ P A D ] \twhere\n",
      "there's        \t[ P A D ] \tthere's\n",
      "massive        \t[ P A D ] \tmassive\n",
      "new            \t[ P A D ] \tnew\n",
      "speciation     \t[ P A D ] \tspeciation\n",
      "based          \t[ P A D ] \tbased\n",
      "on             \t[ P A D ] \ton\n",
      "this           \t[ P A D ] \tthis\n",
      "digital        \t[ P A D ] \tdigital\n",
      "design         \t.         \tdesign.\n",
      "why            \t[ P A D ] \twhy\n",
      "do             \t[ P A D ] \tdo\n",
      "this           \t?         \tthis?\n",
      "i              \t[ P A D ] \ti\n",
      "think          \t[ P A D ] \tthink\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "pretty         \t[ P A D ] \tpretty\n",
      "obvious        \t[ P A D ] \tobvious\n",
      "in             \t[ P A D ] \tin\n",
      "terms          \t[ P A D ] \tterms\n",
      "of             \t[ P A D ] \tof\n",
      "some           \t[ P A D ] \tsome\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "needs          \t.         \tneeds.\n",
      "we're          \t[ P A D ] \twe're\n",
      "about          \t[ P A D ] \tabout\n",
      "to             \t[ P A D ] \tto\n",
      "go             \t[ P A D ] \tgo\n",
      "from           \t[ P A D ] \tfrom\n",
      "six            \t[ P A D ] \tsix\n",
      "and            \t[ P A D ] \tand\n",
      "a              \t[ P A D ] \ta\n",
      "half           \t[ P A D ] \thalf\n",
      "to             \t[ P A D ] \tto\n",
      "9              \t[ P A D ] \t9\n",
      "billion        \t[ P A D ] \tbillion\n",
      "people         \t[ P A D ] \tpeople\n",
      "over           \t[ P A D ] \tover\n",
      "the            \t[ P A D ] \tthe\n",
      "next           \t[ P A D ] \tnext\n",
      "40             \t[ P A D ] \t40\n",
      "years          \t.         \tyears.\n",
      "to             \t[ P A D ] \tto\n",
      "put            \t[ P A D ] \tput\n",
      "it             \t[ P A D ] \tit\n",
      "in             \t[ P A D ] \tin\n",
      "context        \t[ P A D ] \tcontext\n",
      "for            \t[ P A D ] \tfor\n",
      "myself         \t,         \tmyself,\n",
      "i              \t[ P A D ] \ti\n",
      "was            \t[ P A D ] \twas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "born           \t[ P A D ] \tborn\n",
      "in             \t[ P A D ] \tin\n",
      "1946           \t.         \t1946.\n",
      "there's        \t[ P A D ] \tthere's\n",
      "now            \t[ P A D ] \tnow\n",
      "three          \t[ P A D ] \tthree\n",
      "people         \t[ P A D ] \tpeople\n",
      "on             \t[ P A D ] \ton\n",
      "the            \t[ P A D ] \tthe\n",
      "planet         \t[ P A D ] \tplanet\n",
      "for            \t[ P A D ] \tfor\n",
      "every          \t[ P A D ] \tevery\n",
      "one            \t[ P A D ] \tone\n",
      "of             \t[ P A D ] \tof\n",
      "us             \t[ P A D ] \tus\n",
      "that           \t[ P A D ] \tthat\n",
      "existed        \t[ P A D ] \texisted\n",
      "in             \t[ P A D ] \tin\n",
      "1946           \t.         \t1946.\n",
      "within         \t[ P A D ] \twithin\n",
      "40             \t[ P A D ] \t40\n",
      "years          \t,         \tyears,\n",
      "there'll       \t[ P A D ] \tthere'll\n",
      "be             \t[ P A D ] \tbe\n",
      "four           \t.         \tfour.\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "trouble        \t[ P A D ] \ttrouble\n",
      "feeding        \t,         \tfeeding,\n",
      "providing      \t[ P A D ] \tproviding\n",
      "fresh          \t,         \tfresh,\n",
      "clean          \t[ P A D ] \tclean\n",
      "water          \t,         \twater,\n",
      "medicines      \t,         \tmedicines,\n",
      "fuel           \t[ P A D ] \tfuel\n",
      "for            \t[ P A D ] \tfor\n",
      "the            \t[ P A D ] \tthe\n",
      "six            \t[ P A D ] \tsix\n",
      "and            \t[ P A D ] \tand\n",
      "a              \t[ P A D ] \ta\n",
      "half           \t[ P A D ] \thalf\n",
      "billion        \t.         \tbillion.\n",
      "it's           \t[ P A D ] \tit's\n",
      "going          \t[ P A D ] \tgoing\n",
      "to             \t[ P A D ] \tto\n",
      "be             \t[ P A D ] \tbe\n",
      "a              \t[ P A D ] \ta\n",
      "stretch        \t[ P A D ] \tstretch\n",
      "to             \t[ P A D ] \tto\n",
      "do             \t[ P A D ] \tdo\n",
      "it             \t[ P A D ] \tit\n",
      "for            \t[ P A D ] \tfor\n",
      "nine           \t.         \tnine.\n",
      "we             \t[ P A D ] \twe\n",
      "use            \t[ P A D ] \tuse\n",
      "over           \t[ P A D ] \tover\n",
      "5              \t[ P A D ] \t5\n",
      "billion        \t[ P A D ] \tbillion\n",
      "tons           \t[ P A D ] \ttons\n",
      "of             \t[ P A D ] \tof\n",
      "coal           \t,         \tcoal,\n",
      "30             \t[ P A D ] \t30\n",
      "billion        \t[ P A D ] \tbillion\n",
      "plus           \t[ P A D ] \tplus\n",
      "barrels        \t[ P A D ] \tbarrels\n",
      "of             \t[ P A D ] \tof\n",
      "oil            \t.         \toil.\n",
      "that's         \t[ P A D ] \tthat's\n",
      "a              \t[ P A D ] \ta\n",
      "hundred        \t[ P A D ] \thundred\n",
      "million        \t[ P A D ] \tmillion\n",
      "barrels        \t[ P A D ] \tbarrels\n",
      "a              \t[ P A D ] \ta\n",
      "day            \t.         \tday.\n",
      "when           \t[ P A D ] \twhen\n",
      "we             \t[ P A D ] \twe\n",
      "try            \t[ P A D ] \ttry\n",
      "to             \t[ P A D ] \tto\n",
      "think          \t[ P A D ] \tthink\n",
      "of             \t[ P A D ] \tof\n",
      "biological     \t[ P A D ] \tbiological\n",
      "processes      \t[ P A D ] \tprocesses\n",
      "or             \t[ P A D ] \tor\n",
      "any            \t[ P A D ] \tany\n",
      "process        \t[ P A D ] \tprocess\n",
      "to             \t[ P A D ] \tto\n",
      "replace        \t[ P A D ] \treplace\n",
      "that           \t,         \tthat,\n",
      "it's           \t[ P A D ] \tit's\n",
      "going          \t[ P A D ] \tgoing\n",
      "to             \t[ P A D ] \tto\n",
      "be             \t[ P A D ] \tbe\n",
      "a              \t[ P A D ] \ta\n",
      "huge           \t[ P A D ] \thuge\n",
      "challenge      \t.         \tchallenge.\n",
      "then           \t,         \tthen,\n",
      "of             \t[ P A D ] \tof\n",
      "course         \t,         \tcourse,\n",
      "there's        \t[ P A D ] \tthere's\n",
      "all            \t[ P A D ] \tall\n",
      "that           \t[ P A D ] \tthat\n",
      "co2            \t[ P A D ] \tco2\n",
      "from           \t[ P A D ] \tfrom\n",
      "this           \t[ P A D ] \tthis\n",
      "material       \t[ P A D ] \tmaterial\n",
      "that           \t[ P A D ] \tthat\n",
      "ends           \t[ P A D ] \tends\n",
      "up             \t[ P A D ] \tup\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "atmosphere     \t.         \tatmosphere.\n",
      "we             \t[ P A D ] \twe\n",
      "now            \t,         \tnow,\n",
      "from           \t[ P A D ] \tfrom\n",
      "our            \t[ P A D ] \tour\n",
      "discovery      \t[ P A D ] \tdiscovery\n",
      "around         \t[ P A D ] \taround\n",
      "the            \t[ P A D ] \tthe\n",
      "world          \t,         \tworld,\n",
      "have           \t[ P A D ] \thave\n",
      "a              \t[ P A D ] \ta\n",
      "database       \t[ P A D ] \tdatabase\n",
      "with           \t[ P A D ] \twith\n",
      "about          \t[ P A D ] \tabout\n",
      "20             \t[ P A D ] \t20\n",
      "million        \t[ P A D ] \tmillion\n",
      "genes          \t,         \tgenes,\n",
      "and            \t[ P A D ] \tand\n",
      "i              \t[ P A D ] \ti\n",
      "like           \t[ P A D ] \tlike\n",
      "to             \t[ P A D ] \tto\n",
      "think          \t[ P A D ] \tthink\n",
      "of             \t[ P A D ] \tof\n",
      "these          \t[ P A D ] \tthese\n",
      "as             \t[ P A D ] \tas\n",
      "the            \t[ P A D ] \tthe\n",
      "design         \t[ P A D ] \tdesign\n",
      "components     \t[ P A D ] \tcomponents\n",
      "of             \t[ P A D ] \tof\n",
      "the            \t[ P A D ] \tthe\n",
      "future         \t.         \tfuture.\n",
      "the            \t[ P A D ] \tthe\n",
      "electronics    \t[ P A D ] \telectronics\n",
      "industry       \t[ P A D ] \tindustry\n",
      "only           \t[ P A D ] \tonly\n",
      "had            \t[ P A D ] \thad\n",
      "a              \t[ P A D ] \ta\n",
      "dozen          \t[ P A D ] \tdozen\n",
      "or             \t[ P A D ] \tor\n",
      "so             \t[ P A D ] \tso\n",
      "components     \t,         \tcomponents,\n",
      "and            \t[ P A D ] \tand\n",
      "look           \t[ P A D ] \tlook\n",
      "at             \t[ P A D ] \tat\n",
      "the            \t[ P A D ] \tthe\n",
      "diversity      \t[ P A D ] \tdiversity\n",
      "that           \t[ P A D ] \tthat\n",
      "came           \t[ P A D ] \tcame\n",
      "out            \t[ P A D ] \tout\n",
      "of             \t[ P A D ] \tof\n",
      "that           \t.         \tthat.\n",
      "we're          \t[ P A D ] \twe're\n",
      "limited        \t[ P A D ] \tlimited\n",
      "here           \t[ P A D ] \there\n",
      "primarily      \t[ P A D ] \tprimarily\n",
      "by             \t[ P A D ] \tby\n",
      "a              \t[ P A D ] \ta\n",
      "biological     \t[ P A D ] \tbiological\n",
      "reality        \t[ P A D ] \treality\n",
      "and            \t[ P A D ] \tand\n",
      "our            \t[ P A D ] \tour\n",
      "imagination    \t.         \timagination.\n",
      "we             \t[ P A D ] \twe\n",
      "now            \t[ P A D ] \tnow\n",
      "have           \t[ P A D ] \thave\n",
      "techniques     \t,         \ttechniques,\n",
      "because        \t[ P A D ] \tbecause\n",
      "of             \t[ P A D ] \tof\n",
      "these          \t[ P A D ] \tthese\n",
      "rapid          \t[ P A D ] \trapid\n",
      "methods        \t[ P A D ] \tmethods\n",
      "of             \t[ P A D ] \tof\n",
      "synthesis      \t,         \tsynthesis,\n",
      "to             \t[ P A D ] \tto\n",
      "do             \t[ P A D ] \tdo\n",
      "what           \t[ P A D ] \twhat\n",
      "we're          \t[ P A D ] \twe're\n",
      "calling        \t[ P A D ] \tcalling\n",
      "combinatorial  \t[ P A D ] \tcombinatorial\n",
      "genomics       \t.         \tgenomics.\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "the            \t[ P A D ] \tthe\n",
      "ability        \t[ P A D ] \tability\n",
      "now            \t[ P A D ] \tnow\n",
      "to             \t[ P A D ] \tto\n",
      "build          \t[ P A D ] \tbuild\n",
      "a              \t[ P A D ] \ta\n",
      "large          \t[ P A D ] \tlarge\n",
      "robot          \t[ P A D ] \trobot\n",
      "that           \t[ P A D ] \tthat\n",
      "can            \t[ P A D ] \tcan\n",
      "make           \t[ P A D ] \tmake\n",
      "a              \t[ P A D ] \ta\n",
      "million        \t[ P A D ] \tmillion\n",
      "chromosomes    \t[ P A D ] \tchromosomes\n",
      "a              \t[ P A D ] \ta\n",
      "day            \t.         \tday.\n",
      "when           \t[ P A D ] \twhen\n",
      "you            \t[ P A D ] \tyou\n",
      "think          \t[ P A D ] \tthink\n",
      "of             \t[ P A D ] \tof\n",
      "processing     \t[ P A D ] \tprocessing\n",
      "these          \t[ P A D ] \tthese\n",
      "20             \t[ P A D ] \t20\n",
      "million        \t[ P A D ] \tmillion\n",
      "different      \t[ P A D ] \tdifferent\n",
      "genes          \t,         \tgenes,\n",
      "or             \t[ P A D ] \tor\n",
      "trying         \t[ P A D ] \ttrying\n",
      "to             \t[ P A D ] \tto\n",
      "optimize       \t[ P A D ] \toptimize\n",
      "processes      \t[ P A D ] \tprocesses\n",
      "to             \t[ P A D ] \tto\n",
      "produce        \t[ P A D ] \tproduce\n",
      "octane         \t[ P A D ] \toctane\n",
      "or             \t[ P A D ] \tor\n",
      "to             \t[ P A D ] \tto\n",
      "produce        \t[ P A D ] \tproduce\n",
      "pharmaceuticals\t,         \tpharmaceuticals,\n",
      "new            \t[ P A D ] \tnew\n",
      "vaccines       \t,         \tvaccines,\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "change         \t,         \tchange,\n",
      "just           \t[ P A D ] \tjust\n",
      "with           \t[ P A D ] \twith\n",
      "a              \t[ P A D ] \ta\n",
      "small          \t[ P A D ] \tsmall\n",
      "team           \t,         \tteam,\n",
      "do             \t[ P A D ] \tdo\n",
      "more           \t[ P A D ] \tmore\n",
      "molecular      \t[ P A D ] \tmolecular\n",
      "biology        \t[ P A D ] \tbiology\n",
      "than           \t[ P A D ] \tthan\n",
      "the            \t[ P A D ] \tthe\n",
      "last           \t[ P A D ] \tlast\n",
      "20             \t[ P A D ] \t20\n",
      "years          \t[ P A D ] \tyears\n",
      "of             \t[ P A D ] \tof\n",
      "all            \t[ P A D ] \tall\n",
      "science        \t.         \tscience.\n",
      "and            \t[ P A D ] \tand\n",
      "it's           \t[ P A D ] \tit's\n",
      "just           \t[ P A D ] \tjust\n",
      "standard       \t[ P A D ] \tstandard\n",
      "selection      \t.         \tselection.\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "select         \t[ P A D ] \tselect\n",
      "for            \t[ P A D ] \tfor\n",
      "viability      \t,         \tviability,\n",
      "chemical       \t[ P A D ] \tchemical\n",
      "or             \t[ P A D ] \tor\n",
      "fuel           \t[ P A D ] \tfuel\n",
      "production     \t,         \tproduction,\n",
      "vaccine        \t[ P A D ] \tvaccine\n",
      "production     \t,         \tproduction,\n",
      "et             \t[ P A D ] \tet\n",
      "cetera         \t.         \tcetera.\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "a              \t[ P A D ] \ta\n",
      "screen         \t[ P A D ] \tscreen\n",
      "snapshot       \t[ P A D ] \tsnapshot\n",
      "of             \t[ P A D ] \tof\n",
      "some           \t[ P A D ] \tsome\n",
      "true           \t[ P A D ] \ttrue\n",
      "design         \t[ P A D ] \tdesign\n",
      "software       \t[ P A D ] \tsoftware\n",
      "that           \t[ P A D ] \tthat\n",
      "we're          \t[ P A D ] \twe're\n",
      "working        \t[ P A D ] \tworking\n",
      "on             \t[ P A D ] \ton\n",
      "to             \t[ P A D ] \tto\n",
      "actually       \t[ P A D ] \tactually\n",
      "be             \t[ P A D ] \tbe\n",
      "able           \t[ P A D ] \table\n",
      "to             \t[ P A D ] \tto\n",
      "sit            \t[ P A D ] \tsit\n",
      "down           \t[ P A D ] \tdown\n",
      "and            \t[ P A D ] \tand\n",
      "design         \t[ P A D ] \tdesign\n",
      "species        \t[ P A D ] \tspecies\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "computer       \t.         \tcomputer.\n",
      "you            \t[ P A D ] \tyou\n",
      "know           \t,         \tknow,\n",
      "we             \t[ P A D ] \twe\n",
      "don't          \t[ P A D ] \tdon't\n",
      "know           \t[ P A D ] \tknow\n",
      "necessarily    \t[ P A D ] \tnecessarily\n",
      "what           \t[ P A D ] \twhat\n",
      "it'll          \t[ P A D ] \tit'll\n",
      "look           \t[ P A D ] \tlook\n",
      "like           \t.         \tlike.\n",
      "we             \t[ P A D ] \twe\n",
      "know           \t[ P A D ] \tknow\n",
      "exactly        \t[ P A D ] \texactly\n",
      "what           \t[ P A D ] \twhat\n",
      "their          \t[ P A D ] \ttheir\n",
      "genetic        \t[ P A D ] \tgenetic\n",
      "code           \t[ P A D ] \tcode\n",
      "looks          \t[ P A D ] \tlooks\n",
      "like           \t.         \tlike.\n",
      "we're          \t[ P A D ] \twe're\n",
      "focusing       \t[ P A D ] \tfocusing\n",
      "on             \t[ P A D ] \ton\n",
      "now            \t[ P A D ] \tnow\n",
      "fourth         \t[ P A D ] \tfourth\n",
      "generation     \t[ P A D ] \tgeneration\n",
      "fuels          \t.         \tfuels.\n",
      "you've         \t[ P A D ] \tyou've\n",
      "seen           \t[ P A D ] \tseen\n",
      "recently       \t[ P A D ] \trecently\n",
      "corn           \t[ P A D ] \tcorn\n",
      "to             \t[ P A D ] \tto\n",
      "ethanol        \t[ P A D ] \tethanol\n",
      "is             \t[ P A D ] \tis\n",
      "just           \t[ P A D ] \tjust\n",
      "a              \t[ P A D ] \ta\n",
      "bad            \t[ P A D ] \tbad\n",
      "experiment     \t.         \texperiment.\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "second -       \t[ P A D ] \tsecond-\n",
      "and            \t[ P A D ] \tand\n",
      "third          \t[ P A D ] \tthird\n",
      "generation     \t[ P A D ] \tgeneration\n",
      "fuels          \t[ P A D ] \tfuels\n",
      "that           \t[ P A D ] \tthat\n",
      "will           \t[ P A D ] \twill\n",
      "be             \t[ P A D ] \tbe\n",
      "coming         \t[ P A D ] \tcoming\n",
      "out            \t[ P A D ] \tout\n",
      "relatively     \t[ P A D ] \trelatively\n",
      "soon           \t[ P A D ] \tsoon\n",
      "that           \t[ P A D ] \tthat\n",
      "are            \t[ P A D ] \tare\n",
      "sugar          \t,         \tsugar,\n",
      "to             \t[ P A D ] \tto\n",
      "much           \t[ P A D ] \tmuch\n",
      "higher         \t[ P A D ] \thigher\n",
      "value          \t[ P A D ] \tvalue\n",
      "fuels          \t[ P A D ] \tfuels\n",
      "like           \t[ P A D ] \tlike\n",
      "octane         \t[ P A D ] \toctane\n",
      "or             \t[ P A D ] \tor\n",
      "different      \t[ P A D ] \tdifferent\n",
      "types          \t[ P A D ] \ttypes\n",
      "of             \t[ P A D ] \tof\n",
      "butanol        \t.         \tbutanol.\n",
      "but            \t[ P A D ] \tbut\n",
      "the            \t[ P A D ] \tthe\n",
      "only           \t[ P A D ] \tonly\n",
      "way            \t[ P A D ] \tway\n",
      "we             \t[ P A D ] \twe\n",
      "think          \t[ P A D ] \tthink\n",
      "that           \t[ P A D ] \tthat\n",
      "biology        \t[ P A D ] \tbiology\n",
      "can            \t[ P A D ] \tcan\n",
      "have           \t[ P A D ] \thave\n",
      "a              \t[ P A D ] \ta\n",
      "major          \t[ P A D ] \tmajor\n",
      "impact         \t[ P A D ] \timpact\n",
      "without        \t[ P A D ] \twithout\n",
      "further        \t[ P A D ] \tfurther\n",
      "increasing     \t[ P A D ] \tincreasing\n",
      "the            \t[ P A D ] \tthe\n",
      "cost           \t[ P A D ] \tcost\n",
      "of             \t[ P A D ] \tof\n",
      "food           \t[ P A D ] \tfood\n",
      "and            \t[ P A D ] \tand\n",
      "limiting       \t[ P A D ] \tlimiting\n",
      "its            \t[ P A D ] \tits\n",
      "availability   \t[ P A D ] \tavailability\n",
      "is             \t[ P A D ] \tis\n",
      "if             \t[ P A D ] \tif\n",
      "we             \t[ P A D ] \twe\n",
      "start          \t[ P A D ] \tstart\n",
      "with           \t[ P A D ] \twith\n",
      "co2            \t[ P A D ] \tco2\n",
      "as             \t[ P A D ] \tas\n",
      "its            \t[ P A D ] \tits\n",
      "feedstock      \t,         \tfeedstock,\n",
      "and            \t[ P A D ] \tand\n",
      "so             \t[ P A D ] \tso\n",
      "we're          \t[ P A D ] \twe're\n",
      "working        \t[ P A D ] \tworking\n",
      "with           \t[ P A D ] \twith\n",
      "designing      \t[ P A D ] \tdesigning\n",
      "cells          \t[ P A D ] \tcells\n",
      "to             \t[ P A D ] \tto\n",
      "go             \t[ P A D ] \tgo\n",
      "down           \t[ P A D ] \tdown\n",
      "this           \t[ P A D ] \tthis\n",
      "road           \t,         \troad,\n",
      "and            \t[ P A D ] \tand\n",
      "we             \t[ P A D ] \twe\n",
      "think          \t[ P A D ] \tthink\n",
      "we'll          \t[ P A D ] \twe'll\n",
      "have           \t[ P A D ] \thave\n",
      "the            \t[ P A D ] \tthe\n",
      "first          \t[ P A D ] \tfirst\n",
      "fourth         \t[ P A D ] \tfourth\n",
      "generation     \t[ P A D ] \tgeneration\n",
      "fuels          \t[ P A D ] \tfuels\n",
      "in             \t[ P A D ] \tin\n",
      "about          \t[ P A D ] \tabout\n",
      "18             \t[ P A D ] \t18\n",
      "months         \t.         \tmonths.\n",
      "sunlight       \t[ P A D ] \tsunlight\n",
      "and            \t[ P A D ] \tand\n",
      "co2            \t[ P A D ] \tco2\n",
      "is             \t[ P A D ] \tis\n",
      "one            \t[ P A D ] \tone\n",
      "method         \t,         \tmethod,\n",
      "but            \t[ P A D ] \tbut\n",
      "in             \t[ P A D ] \tin\n",
      "our            \t[ P A D ] \tour\n",
      "discovery      \t[ P A D ] \tdiscovery\n",
      "around         \t[ P A D ] \taround\n",
      "the            \t[ P A D ] \tthe\n",
      "world          \t,         \tworld,\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "all            \t[ P A D ] \tall\n",
      "kinds          \t[ P A D ] \tkinds\n",
      "of             \t[ P A D ] \tof\n",
      "other          \t[ P A D ] \tother\n",
      "methods        \t.         \tmethods.\n",
      "this           \t[ P A D ] \tthis\n",
      "is             \t[ P A D ] \tis\n",
      "an             \t[ P A D ] \tan\n",
      "organism       \t[ P A D ] \torganism\n",
      "we             \t[ P A D ] \twe\n",
      "described      \t[ P A D ] \tdescribed\n",
      "in             \t[ P A D ] \tin\n",
      "1996           \t.         \t1996.\n",
      "it             \t[ P A D ] \tit\n",
      "lives          \t[ P A D ] \tlives\n",
      "in             \t[ P A D ] \tin\n",
      "the            \t[ P A D ] \tthe\n",
      "deep           \t[ P A D ] \tdeep\n",
      "ocean          \t,         \tocean,\n",
      "about          \t[ P A D ] \tabout\n",
      "a              \t[ P A D ] \ta\n",
      "mile           \t[ P A D ] \tmile\n",
      "and            \t[ P A D ] \tand\n",
      "a              \t[ P A D ] \ta\n",
      "half           \t[ P A D ] \thalf\n",
      "deep           \t,         \tdeep,\n",
      "almost         \t[ P A D ] \talmost\n",
      "at             \t[ P A D ] \tat\n",
      "boiling        \t[ P A D ] \tboiling\n",
      "water          \t[ P A D ] \twater\n",
      "temperatures   \t.         \ttemperatures.\n",
      "it             \t[ P A D ] \tit\n",
      "takes          \t[ P A D ] \ttakes\n",
      "co2            \t[ P A D ] \tco2\n",
      "to             \t[ P A D ] \tto\n",
      "methane        \t[ P A D ] \tmethane\n",
      "using          \t[ P A D ] \tusing\n",
      "molecular      \t[ P A D ] \tmolecular\n",
      "hydrogen       \t[ P A D ] \thydrogen\n",
      "as             \t[ P A D ] \tas\n",
      "its            \t[ P A D ] \tits\n",
      "energy         \t[ P A D ] \tenergy\n",
      "source         \t.         \tsource.\n",
      "we're          \t[ P A D ] \twe're\n",
      "looking        \t[ P A D ] \tlooking\n",
      "to             \t[ P A D ] \tto\n",
      "see            \t[ P A D ] \tsee\n",
      "if             \t[ P A D ] \tif\n",
      "we             \t[ P A D ] \twe\n",
      "can            \t[ P A D ] \tcan\n",
      "take           \t[ P A D ] \ttake\n",
      "captured       \t[ P A D ] \tcaptured\n",
      "co2            \t,         \tco2,\n",
      "which          \t[ P A D ] \twhich\n",
      "can            \t[ P A D ] \tcan\n",
      "easily         \t[ P A D ] \teasily\n",
      "be             \t[ P A D ] \tbe\n",
      "piped          \t[ P A D ] \tpiped\n",
      "to             \t[ P A D ] \tto\n",
      "sites          \t,         \tsites,\n",
      "convert        \t[ P A D ] \tconvert\n",
      "that           \t[ P A D ] \tthat\n",
      "co2            \t[ P A D ] \tco2\n",
      "back           \t[ P A D ] \tback\n",
      "into           \t[ P A D ] \tinto\n",
      "fuel           \t,         \tfuel,\n",
      "to             \t[ P A D ] \tto\n",
      "drive          \t[ P A D ] \tdrive\n",
      "this           \t[ P A D ] \tthis\n",
      "process        \t.         \tprocess.\n",
      "so             \t[ P A D ] \tso\n",
      "in             \t[ P A D ] \tin\n",
      "a              \t[ P A D ] \ta\n",
      "short          \t[ P A D ] \tshort\n",
      "period         \t[ P A D ] \tperiod\n",
      "of             \t[ P A D ] \tof\n",
      "time           \t,         \ttime,\n",
      "we             \t[ P A D ] \twe\n",
      "think          \t[ P A D ] \tthink\n",
      "that           \t[ P A D ] \tthat\n",
      "we             \t[ P A D ] \twe\n",
      "might          \t[ P A D ] \tmight\n",
      "be             \t[ P A D ] \tbe\n",
      "able           \t[ P A D ] \table\n",
      "to             \t[ P A D ] \tto\n",
      "increase       \t[ P A D ] \tincrease\n",
      "what           \t[ P A D ] \twhat\n",
      "the            \t[ P A D ] \tthe\n",
      "basic          \t[ P A D ] \tbasic\n",
      "question       \t[ P A D ] \tquestion\n",
      "is             \t[ P A D ] \tis\n",
      "of, what       \t[ P A D ] \tof,what\n",
      "is             \t[ P A D ] \tis\n",
      "life?          \t,         \tlife?,\n",
      "we're          \t[ P A D ] \twe're\n",
      "truly          \t,         \ttruly,\n",
      "you            \t[ P A D ] \tyou\n",
      "know           \t,         \tknow,\n",
      "have           \t[ P A D ] \thave\n",
      "modest         \t[ P A D ] \tmodest\n",
      "goals          \t[ P A D ] \tgoals\n",
      "of             \t[ P A D ] \tof\n",
      "replacing      \t[ P A D ] \treplacing\n",
      "the            \t[ P A D ] \tthe\n",
      "whole          \t[ P A D ] \twhole\n",
      "petrol         \t[ P A D ] \tpetrol\n",
      "chemical       \t[ P A D ] \tchemical\n",
      "industry       \t.         \tindustry.\n",
      "yeah           \t.         \tyeah.\n",
      "if             \t[ P A D ] \tif\n",
      "you            \t[ P A D ] \tyou\n",
      "can't          \t[ P A D ] \tcan't\n",
      "do             \t[ P A D ] \tdo\n",
      "that           \t[ P A D ] \tthat\n",
      "at             \t[ P A D ] \tat\n",
      "ted            \t,         \tted,\n",
      "where          \t[ P A D ] \twhere\n",
      "can            \t[ P A D ] \tcan\n",
      "you            \t?         \tyou?\n",
      "become         \t[ P A D ] \tbecome\n",
      "a              \t[ P A D ] \ta\n",
      "major          \t[ P A D ] \tmajor\n",
      "source         \t[ P A D ] \tsource\n",
      "of             \t[ P A D ] \tof\n",
      "energy         \t.         \tenergy.\n",
      "but            \t[ P A D ] \tbut\n",
      "also           \t,         \talso,\n",
      "we're          \t[ P A D ] \twe're\n",
      "now            \t[ P A D ] \tnow\n",
      "working        \t[ P A D ] \tworking\n",
      "on             \t[ P A D ] \ton\n",
      "using          \t[ P A D ] \tusing\n",
      "these          \t[ P A D ] \tthese\n",
      "same           \t[ P A D ] \tsame\n",
      "tools          \t[ P A D ] \ttools\n",
      "to             \t[ P A D ] \tto\n",
      "come           \t[ P A D ] \tcome\n",
      "up             \t[ P A D ] \tup\n",
      "with           \t[ P A D ] \twith\n",
      "instant        \t[ P A D ] \tinstant\n",
      "sets           \t[ P A D ] \tsets\n",
      "of             \t[ P A D ] \tof\n",
      "vaccines       \t.         \tvaccines.\n",
      "you've         \t[ P A D ] \tyou've\n",
      "seen           \t[ P A D ] \tseen\n",
      "this           \t[ P A D ] \tthis\n",
      "year           \t[ P A D ] \tyear\n",
      "with           \t[ P A D ] \twith\n",
      "flu            \t,         \tflu,\n",
      "we're          \t[ P A D ] \twe're\n",
      "always         \t[ P A D ] \talways\n",
      "a              \t[ P A D ] \ta\n",
      "year           \t[ P A D ] \tyear\n",
      "behind         \t[ P A D ] \tbehind\n",
      "and            \t[ P A D ] \tand\n",
      "a              \t[ P A D ] \ta\n",
      "dollar         \t[ P A D ] \tdollar\n",
      "short          \t[ P A D ] \tshort\n",
      "when           \t[ P A D ] \twhen\n",
      "it             \t[ P A D ] \tit\n",
      "comes          \t[ P A D ] \tcomes\n",
      "to             \t[ P A D ] \tto\n",
      "the            \t[ P A D ] \tthe\n",
      "right          \t[ P A D ] \tright\n",
      "vaccine        \t.         \tvaccine.\n",
      "i              \t[ P A D ] \ti\n",
      "think          \t[ P A D ] \tthink\n",
      "that           \t[ P A D ] \tthat\n",
      "can            \t[ P A D ] \tcan\n",
      "be             \t[ P A D ] \tbe\n",
      "changed        \t[ P A D ] \tchanged\n",
      "by             \t[ P A D ] \tby\n",
      "building       \t[ P A D ] \tbuilding\n",
      "combinatorial  \t[ P A D ] \tcombinatorial\n",
      "vaccines       \t[ P A D ] \tvaccines\n",
      "in             \t[ P A D ] \tin\n",
      "advance        \t.         \tadvance.\n",
      "here's         \t[ P A D ] \there's\n",
      "what           \t[ P A D ] \twhat\n",
      "the            \t[ P A D ] \tthe\n",
      "future         \t[ P A D ] \tfuture\n",
      "may            \t[ P A D ] \tmay\n",
      "begin          \t[ P A D ] \tbegin\n",
      "to             \t[ P A D ] \tto\n",
      "look           \t[ P A D ] \tlook\n",
      "like           \t[ P A D ] \tlike\n",
      "with           \t[ P A D ] \twith\n",
      "changing       \t,         \tchanging,\n",
      "now            \t,         \tnow,\n",
      "the            \t[ P A D ] \tthe\n",
      "evolutionary   \t[ P A D ] \tevolutionary\n",
      "tree           \t,         \ttree,\n",
      "speeding       \t[ P A D ] \tspeeding\n",
      "up             \t[ P A D ] \tup\n",
      "evolution      \t[ P A D ] \tevolution\n",
      "with           \t[ P A D ] \twith\n",
      "synthetic      \t[ P A D ] \tsynthetic\n",
      "bacteria       \t,         \tbacteria,\n",
      "archea         \t,         \tarchea,\n",
      "and            \t[ P A D ] \tand\n",
      "eventually     \t[ P A D ] \teventually\n",
      "eukaryotes     \t.         \teukaryotes.\n",
      "we're          \t[ P A D ] \twe're\n",
      "a              \t[ P A D ] \ta\n",
      "ways           \t[ P A D ] \tways\n",
      "away           \t[ P A D ] \taway\n",
      "from           \t[ P A D ] \tfrom\n",
      "improving      \t[ P A D ] \timproving\n",
      "people         \t.         \tpeople.\n",
      "our            \t[ P A D ] \tour\n",
      "goal           \t[ P A D ] \tgoal\n",
      "is             \t[ P A D ] \tis\n",
      "just           \t[ P A D ] \tjust\n",
      "to             \t[ P A D ] \tto\n",
      "make           \t[ P A D ] \tmake\n",
      "sure           \t[ P A D ] \tsure\n",
      "that           \t[ P A D ] \tthat\n",
      "we             \t[ P A D ] \twe\n",
      "have           \t[ P A D ] \thave\n",
      "a              \t[ P A D ] \ta\n",
      "chance         \t[ P A D ] \tchance\n",
      "to             \t[ P A D ] \tto\n",
      "survive        \t[ P A D ] \tsurvive\n",
      "long           \t[ P A D ] \tlong\n",
      "enough         \t[ P A D ] \tenough\n",
      "to             \t[ P A D ] \tto\n",
      "maybe          \t[ P A D ] \tmaybe\n",
      "do             \t[ P A D ] \tdo\n",
      "that           \t.         \tthat.\n",
      "thank          \t[ P A D ] \tthank\n",
      "you            \t[ P A D ] \tyou\n",
      "very           \t[ P A D ] \tvery\n",
      "much           \t.         \tmuch.\n",
      "[SEP]          \t[ U N K ] \t\n"
     ]
    }
   ],
   "source": [
    "e = []\n",
    "i = 0\n",
    "\n",
    "raw_words = datasets[1][2].split(' ')\n",
    "\n",
    "for te, ta in zip(encoded_texts[1][2], targets[1][2]):\n",
    "    if ta == -1:\n",
    "        e.append(te)\n",
    "    else:\n",
    "        e.append(te)\n",
    "        print(f\"{tokenizer.decode(e):15}\\t{tokenizer.decode(target2id[ta]):10}\\t{raw_words[i]}\")\n",
    "        e = []\n",
    "        i += 1\n",
    "print(f\"{tokenizer.decode(e):15}\\t{tokenizer.decode(target2id[ta]):10}\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] you know i've talked about some of these projects before about the human genome and what that might mean and discovering new sets of genes we're actually starting at a new point we've been digitizing biology and now we're trying to go from that digital code into a new phase of biology with designing and synthesizing life so we've always been trying to ask big questions., what is life? is something that i think many biologists have been trying to understand at various levels we've tried various approaches paring it down to minimal components we've been digitizing it now for almost 20 years when we sequenced the human genome it was going from the analog world of biology into the digital world of the computer now we're trying to ask can we regenerate life or can we create new life out of this digital universe this is the map of a small organism mycoplasma genitalium that has the smallest genome for a species that can self replicate in the laboratory and we've been trying to just see if we can come up with an even smaller genome we're able to knock out on the order of a hundred genes out of the 500 or so that are here but when we look at its metabolic map it's relatively simple compared to ours trust me this is simple but when we look at all the genes that we can knock out one at a time it's very unlikely that this would yield a living cell so we decided the only way forward was to actually synthesize this chromosome so we could vary the components to ask some of these most fundamental questions and so we started down the road of, can we synthesize a chromosome? can chemistry permit making these really large molecules where we've never been before and if we do can we boot up a chromosome a chromosome by the way is just a piece of inert chemical material so our pace of digitizing life has been increasing at an exponential pace our ability to write the genetic code has been moving pretty slowly but has been increasing and our latest point would put it on now an exponential curve we started this over 15 years ago it took several stages in fact starting with a bioethical review before we did the first experiments but it turns out synthesizing dna is very difficult there's tens of thousands of machines around the world that make small pieces of dna 30 to 50 letters in length and it's a degenerate process so the longer you make the piece the more errors there are so we had to create a new method for putting these little pieces together and correct all the errors and this was our first attempt starting with the digital information of the genome of phi x 174 it's a small virus that kills bacteria we designed the pieces went through our error correction and had a dna molecule of about 5, 000 letters the exciting phase came when we took this piece of inert chemical and put it in the bacteria and the bacteria started to read this genetic code made the viral particles the viral particles then were released from the cells then came back and killed the e coli i was talking to the oil industry recently and i said they clearly understood that model they laughed more than you guys are and so we think this is a situation where the software can actually build its own hardware in a biological system but we wanted to go much larger we wanted to build the entire bacterial chromosome it's over 580, 000 letters of genetic code so we thought we'd build them in cassettes the size of the viruses so we could actually vary the cassettes to understand what the actual components of a living cell are design is critical and if you're starting with digital information in the computer that digital information has to be really accurate when we first sequenced this genome in 1995 the standard of accuracy was one error per 10, 000 base pairs we actually found on resequencing it 30 errors had we used that original sequence it never would have been able to be booted up part of the design is designing pieces that are 50 letters long that have to overlap with all the other 50 - letter pieces to build smaller sub units we have to design so they can go together we design unique elements into this you may have read that we put watermarks in think of this we have a four letter genetic code a c g and t triplets of that letter those letters code for roughly 20 amino acids that there's a single letter designation for each of the amino acids so we can use the genetic code to write out words sentences thoughts initially all we did was autograph it some people were disappointed there was not poetry we designed these pieces so we can just chew back with enzymes there's enzymes that repair them and put them together and we started making pieces starting with pieces that were five to 7, 000 letters fit those together to make 24, 000 - letter pieces then put sets of those going up to 72, 000 at each stage we grew up these pieces in abundance so we could sequence them because we're trying to create a process that's extremely robust that you can see in a minute we're trying to get to the point of automation so this looks like a basketball playoff when we get into these really large pieces over 100, 000 base pairs they won't any longer grow readily in e coli it exhausts all the modern tools of molecular biology and so we turned to other mechanisms we knew there's a mechanism called homologous recombination that biology uses to repair dna that can put pieces together here's an example of it there's an organism called deinococcus radiodurans that can take three millions rads of radiation you can see in the top panel its chromosome just gets blown apart 12 to 24 hours later it put it back together exactly as it was before we have thousands of organisms that can do this these organisms can be totally desiccated they can live in a vacuum i am absolutely certain that life can exist in outer space move around find a new aqueous environment in fact nasa has shown a lot of this is out there here's an actual micrograph of the molecule we built using these processes actually just using yeast mechanisms with the right design of the pieces we put them in yeast puts them together automatically this is not an electron micrograph this is just a regular photomicrograph it's such a large molecule we can see it with a light microscope these are pictures over about a six second period so this is the publication we had just a short while ago this is over 580, 000 letters of genetic code it's the largest molecule ever made by humans of a defined structure it's over 300 million molecular weight if we printed out at a 10 font with no spacing it takes 142 pages just to print this genetic code well how do we boot up a chromosome how do we activate this obviously with a virus it's pretty simple it's much more complicated dealing with bacteria it's also simpler when you go into eukaryotes like ourselves you can just pop out the nucleus and pop in another one and that's what you've all heard about with cloning with bacteria archaea the chromosome is integrated into the cell but we recently showed that we can do a complete transplant of a chromosome from one cell to another and activate it we purified a chromosome from one microbial species roughly these two are as distant as human and mice we added a few extra genes so we could select for this chromosome we digested it with enzymes to kill all the proteins and it was pretty stunning when we put this in the cell and you'll appreciate our very sophisticated graphics here the new chromosome went into the cell in fact we thought this might be as far as it went but we tried to design the process a little bit further this is a major mechanism of evolution right here we find all kinds of species that have taken up a second chromosome or a third one from somewhere adding thousands of new traits in a second to that species so people who think of evolution as just one gene changing at a time have missed much of biology there's enzymes called restriction enzymes that actually digest dna the chromosome that was in the cell doesn't have one the cell the chromosome we put in does it got expressed and it recognized the other chromosome as foreign material chewed it up and so we ended up just with the cell with the new chromosome it turned blue because of the genes we put in it and with a very short period of time all the characteristics of one species were lost and it converted totally into the new species based on the new software that we put in the cell all the proteins changed the membranes changed when we read the genetic code it's exactly what we had transferred in so this may sound like genomic alchemy but we can by moving the software dna around change things quite dramatically now i've argued this is not genesis this is building on three and a half billion years of evolution and i've argued that we're about to perhaps create a new version of the cambrian explosion where there's massive new speciation based on this digital design why do this i think this is pretty obvious in terms of some of the needs we're about to go from six and a half to 9 billion people over the next 40 years to put it in context for myself i was born in 1946 there's now three people on the planet for every one of us that existed in 1946 within 40 years there'll be four we have trouble feeding providing fresh clean water medicines fuel for the six and a half billion it's going to be a stretch to do it for nine we use over 5 billion tons of coal 30 billion plus barrels of oil that's a hundred million barrels a day when we try to think of biological processes or any process to replace that it's going to be a huge challenge then of course there's all that co2 from this material that ends up in the atmosphere we now from our discovery around the world have a database with about 20 million genes and i like to think of these as the design components of the future the electronics industry only had a dozen or so components and look at the diversity that came out of that we're limited here primarily by a biological reality and our imagination we now have techniques because of these rapid methods of synthesis to do what we're calling combinatorial genomics we have the ability now to build a large robot that can make a million chromosomes a day when you think of processing these 20 million different genes or trying to optimize processes to produce octane or to produce pharmaceuticals new vaccines we can change just with a small team do more molecular biology than the last 20 years of all science and it's just standard selection we can select for viability chemical or fuel production vaccine production et cetera this is a screen snapshot of some true design software that we're working on to actually be able to sit down and design species in the computer you know we don't know necessarily what it'll look like we know exactly what their genetic code looks like we're focusing on now fourth generation fuels you've seen recently corn to ethanol is just a bad experiment we have second - and third generation fuels that will be coming out relatively soon that are sugar to much higher value fuels like octane or different types of butanol but the only way we think that biology can have a major impact without further increasing the cost of food and limiting its availability is if we start with co2 as its feedstock and so we're working with designing cells to go down this road and we think we'll have the first fourth generation fuels in about 18 months sunlight and co2 is one method but in our discovery around the world we have all kinds of other methods this is an organism we described in 1996 it lives in the deep ocean about a mile and a half deep almost at boiling water temperatures it takes co2 to methane using molecular hydrogen as its energy source we're looking to see if we can take captured co2 which can easily be piped to sites convert that co2 back into fuel to drive this process so in a short period of time we think that we might be able to increase what the basic question is of, what is life? we're truly you know have modest goals of replacing the whole petrol chemical industry yeah if you can't do that at ted where can you become a major source of energy but also we're now working on using these same tools to come up with instant sets of vaccines you've seen this year with flu we're always a year behind and a dollar short when it comes to the right vaccine i think that can be changed by building combinatorial vaccines in advance here's what the future may begin to look like with changing now the evolutionary tree speeding up evolution with synthetic bacteria archea and eventually eukaryotes we're a ways away from improving people our goal is just to make sure that we have a chance to survive long enough to maybe do that thank you very much [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(encoded_texts[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
